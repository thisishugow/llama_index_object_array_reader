{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import importlib\n",
    "import textwrap\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext, set_global_tokenizer, PromptHelper, StorageContext\n",
    "from llama_index.core.text_splitter import SentenceSplitter\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from llamaindex_object_array_reader.dataset import simple_ols # import a simple dataset \n",
    "from llama_index.legacy.llms import HuggingFaceLLM\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import BitsAndBytesConfig\n",
    "from llama_index.llms.ollama import Ollama\n",
    "# from langchain.embeddings import HuggingFaceEmbedding, HuggingFaceInstructEmbeddings\n",
    "from llama_index.legacy.embeddings import HuggingFaceEmbedding\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from argparse import Namespace\n",
    "from chromadb import Collection, PersistentClient\n",
    "from dotenv import load_dotenv\n",
    "from llamaindex_object_array_reader import ObjectArrayReader\n",
    "from llama_index.core.callbacks import CallbackManager, LlamaDebugHandler\n",
    "import nest_asyncio\n",
    "\n",
    "# å…è®¸åµŒå¥—äº‹ä»¶å¾ªçŽ¯\n",
    "nest_asyncio.apply()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from llamaindex_object_array_reader._logging import logger\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "log = logger\n",
    "log.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
    "callback_manager = CallbackManager([llama_debug])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obsolete\n",
    "# if os.path.exists('my_cred.py'):\n",
    "#     my_cred = importlib.import_module('my_cred')\n",
    "#     os.environ['OPENAI_API_KEY'] = my_cred.OPENAI_API_KEY\n",
    "# else:\n",
    "#     # Set your OPENAI API Key\n",
    "#     os.environ['OPENAI_API_KEY'] = \"vy-...cH5N\"\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
    "HF_TOKEN = os.environ['HF_TOKEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_resp(msg, max_len:int=55):\n",
    "    \"\"\"å°†æ–‡æœ¬åˆ†å‰²ä¸ºæ¯è¡Œæœ€å¤§é•¿åº¦çš„å­å­—ç¬¦ä¸²\n",
    "    \"\"\"\n",
    "    divider: str = '\\n'+ '*'*60+'\\n'\n",
    "    msg = textwrap.fill(msg, width=max_len)\n",
    "    print(f\"\"\"\\u2705 RESPONSE:{divider}\\n{msg}\\n{divider} \\U0001F6A9END OF RESPONSE\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models:Namespace = Namespace(\n",
    "    BERT_BASE_CHINESE=\"bert-base-chinese\",\n",
    "    LLAMA2_CHINESE_7B_CHAT=\"FlagAlpha/Llama2-Chinese-7b-Chat\", #18G needed\n",
    "    LLAMA2_7B_CHAT_HF=\"meta-llama/Llama-2-7b-chat-hf\", #18G needed\n",
    "    BLOOM_560M=\"bigscience/bloom-560m\", #18G needed\n",
    "    BLOOMZ_560M=\"bigscience/bloomz-560m\", #18G needed\n",
    "    GPT2=\"GPT2\", #18G needed\n",
    "    ALL_MPNET_BASE_V2=\"sentence-transformers/all-mpnet-base-v2\", #18G needed\n",
    "    MISTRAL_7B_INSTRUCT_V0_1=\"mistralai/Mistral-7B-Instruct-v0.1\", #18G needed\n",
    "    STARLING_LM_7B=\"berkeley-nest/Starling-LM-7B-alpha\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the check point\n",
    "check_point:str = models.ALL_MPNET_BASE_V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new HTTPS connection (1): huggingface.co:443\n",
      "https://huggingface.co:443 \"HEAD /sentence-transformers/all-mpnet-base-v2/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(check_point)\n",
    "set_global_tokenizer(tokenizer)\n",
    "\n",
    "# Alternatively, using a local LLM\n",
    "USE_LOCAL:bool = True\n",
    "if USE_LOCAL:\n",
    "    # llm = Ollama(model=\"llama2-chinese\")\n",
    "    # llm = Ollama(model=\"starling-lm:7b-alpha-q3_K_M\")\n",
    "    llm = Ollama(model=\"mistral\")\n",
    "    \n",
    "else: \n",
    "    llm = HuggingFaceLLM(\n",
    "        model_name=check_point,\n",
    "        tokenizer_name=check_point,\n",
    "        context_window=512,\n",
    "        model_kwargs={\n",
    "            # 'torch_dtype':torch.float16,\n",
    "            \"token\": HF_TOKEN,\n",
    "            'load_in_8bit':False, #No, the bitsandbytes library only works on CUDA GPU. So it must set to 'False' as running on mac os. \n",
    "            'offload_folder':\"offload_folder\",\n",
    "            'offload_state_dict':True,\n",
    "            'is_decoder': True if check_point==models.BERT_BASE_CHINESE else None,\n",
    "            },\n",
    "        tokenizer_kwargs={\n",
    "            \"token\": HF_TOKEN,\n",
    "            \"return_tensors\":'pt',},\n",
    "        device_map=\"auto\" if check_point!=models.BERT_BASE_CHINESE else \"mps\", \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://huggingface.co:443 \"HEAD /sentence-transformers/all-mpnet-base-v2/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "Starting new HTTPS connection (1): huggingface.co:443\n",
      "https://huggingface.co:443 \"GET /sentence-transformers/all-mpnet-base-v2/raw/main/1_Pooling/config.json HTTP/1.1\" 200 190\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbedding(\n",
    "    model_name=check_point,\n",
    "    tokenizer=tokenizer,\n",
    "    cache_folder=\"cache_folder\",\n",
    "    max_length=512,\n",
    "    device=\"mps\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = SentenceSplitter(chunk_size=512, chunk_overlap=64)\n",
    "prompt_helper = PromptHelper(\n",
    "    context_window=512,\n",
    "    num_output=256,\n",
    "    chunk_overlap_ratio=0.1,\n",
    "    chunk_size_limit=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [SimpleDirectoryReader] Total files added: 3\n"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(\"test_docs/simple_txt_short_en\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Adding chunk: You can do data integration, management, analys...\n",
      "> Adding chunk: Colosscious' flagship product, Pharmquer, is an...\n",
      "> Adding chunk: Welcome to Colosscious. \n",
      "We are the expert who ...\n",
      "Total nodes: 3\n",
      "Node ID: cde41ebf-9512-4793-a8d6-b3002b2e527d\n",
      "Text: You can do data integration, management, analysis and composing\n",
      "reports and dashboards with Pharmquer, and then automatize all your\n",
      "works.\n",
      "---\n",
      "Node ID: e5bfe2b0-5ee3-4b74-9d34-e2b77c28a40e\n",
      "Text: Colosscious' flagship product, Pharmquer, is an enterprise level\n",
      "software of manufacturing and business intelligence, which is\n",
      "architected especially for the industry.\n",
      "---\n",
      "Node ID: 7e1706e8-8321-409c-b1fd-72891a749953\n",
      "Text: Welcome to Colosscious.  We are the expert who spotlight-focus\n",
      "on providing the digital technology to bio and pharmaceutical\n",
      "companies, engaging in boosting the performances of new drug\n",
      "developments, quality control, manufacturing processes, and reducing\n",
      "the costs and duration by Big Data.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Assuming documents have already been loaded\n",
    "# Initialize the parser\n",
    "parser = SimpleNodeParser.from_defaults(chunk_size=512, chunk_overlap=20)\n",
    "# Parse documents into nodes\n",
    "nodes = parser.get_nodes_from_documents(documents)\n",
    "print('Total nodes:', len(nodes))\n",
    "for _, n in enumerate(nodes):\n",
    "    print(n)\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 02:05:38,359 - chromadb.telemetry.product.posthog - \u001b[32;20mINFO\u001b[0m - (posthog.py:20) - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "Starting component System\n",
      "Starting component Posthog\n",
      "Starting component OpenTelemetryClient\n",
      "Starting component SimpleAssignmentPolicy\n",
      "Starting component SqliteDB\n",
      "Starting component LocalSegmentManager\n",
      "Starting component SegmentAPI\n"
     ]
    }
   ],
   "source": [
    "V_DB_NAME = \"chromadb\"\n",
    "chroma_client = PersistentClient(V_DB_NAME)\n",
    "COLLECTION_NAME:str = 'test'\n",
    "chroma_collection:Collection = chroma_client.get_or_create_collection(COLLECTION_NAME)\n",
    "vector_store = ChromaVectorStore(chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new HTTPS connection (1): us-api.i.posthog.com:443\n",
      "https://us-api.i.posthog.com:443 \"POST /batch/ HTTP/1.1\" 200 None\n"
     ]
    }
   ],
   "source": [
    "for n in nodes:\n",
    "    print(storage_context.docstore.document_exists(n.id_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and store new embeddings to ChromaDB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cb/80zl4p1j4557_30l5vq25k6h0000gn/T/ipykernel_35003/4245882545.py:3: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(llm=llm, embed_model=embedding_model, text_splitter=text_splitter,\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Generating embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 13.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting component PersistentLocalHnswSegment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-02-13 02:05:44,692 - chromadb.segment.impl.vector.local_persistent_hnsw - \u001b[33;20mWARNING\u001b[0m - (local_persistent_hnsw.py:271) - Add of existing embedding ID: dc0f865e-90c8-42b0-9239-19625ebcef35 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: dc0f865e-90c8-42b0-9239-19625ebcef35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 02:05:44,693 - chromadb.segment.impl.vector.local_persistent_hnsw - \u001b[33;20mWARNING\u001b[0m - (local_persistent_hnsw.py:271) - Add of existing embedding ID: 1f7abdb8-4dbb-4f9d-9398-f59fb630b862 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: 1f7abdb8-4dbb-4f9d-9398-f59fb630b862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 02:05:44,693 - chromadb.segment.impl.vector.local_persistent_hnsw - \u001b[33;20mWARNING\u001b[0m - (local_persistent_hnsw.py:271) - Add of existing embedding ID: cb553733-838a-421b-89bf-c582fe90182a \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: cb553733-838a-421b-89bf-c582fe90182a\n",
      "**********\n",
      "Trace: index_construction\n",
      "    |_embedding ->  0.222214 seconds\n",
      "**********\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://us-api.i.posthog.com:443 \"POST /batch/ HTTP/1.1\" 200 None\n"
     ]
    }
   ],
   "source": [
    "storage_context.docstore.add_documents(nodes)\n",
    "\n",
    "service_context = ServiceContext.from_defaults(llm=llm, embed_model=embedding_model, text_splitter=text_splitter,\n",
    "    prompt_helper=prompt_helper, callback_manager=callback_manager)\n",
    "# index = VectorStoreIndex.from_documents(\n",
    "#     documents, service_context=service_context, storage_context=storage_context, show_progress=True,\n",
    "# )\n",
    "index = VectorStoreIndex(\n",
    "    nodes, service_context=service_context, storage_context=storage_context, show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2058,  8906, 15098, 18440,  2083,  1033]], device='mps:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\n",
    "    [\"What Colosscious do?\"],\n",
    "    return_tensors=\"pt\",\n",
    "    add_special_tokens=False,\n",
    ").input_ids.to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Top 1 nodes:\n",
      "> [Node cb130b57-5f50-4276-9215-38aa878a7381] [Similarity score: 0.4660001156353038] Welcome to Colosscious. \n",
      "We are the expert who spotlight-focus on providing the digital technolog...\n",
      "> [Node 7e1706e8-8321-409c-b1fd-72891a749953] [Similarity score: 0.4660001156353038] Welcome to Colosscious. \n",
      "We are the expert who spotlight-focus on providing the digital technolog...\n",
      "> Top 2 nodes:\n",
      "> [Node cb130b57-5f50-4276-9215-38aa878a7381] [Similarity score:             0.466] Welcome to Colosscious. \n",
      "We are the expert who spotlight-focus on providing the digital technolog...\n",
      "> [Node 7e1706e8-8321-409c-b1fd-72891a749953] [Similarity score:             0.466] Welcome to Colosscious. \n",
      "We are the expert who spotlight-focus on providing the digital technolog...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2d1dfdf60>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "https://us-api.i.posthog.com:443 \"POST /batch/ HTTP/1.1\" 200 None\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Tue, 13 Feb 2024 01:05:52 GMT'), (b'Content-Length', b'604')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 02:05:52,363 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "âœ… RESPONSE:\n",
      "************************************************************\n",
      "\n",
      " Colosconscious specializes in delivering digital\n",
      "technology solutions to bio and pharmaceutical\n",
      "companies, with a focus on enhancing new drug\n",
      "development, improving quality control, optimizing\n",
      "manufacturing processes, and reducing costs and\n",
      "duration through Big Data. No specific flagship product\n",
      "is mentioned in the context provided.\n",
      "\n",
      "************************************************************\n",
      " ðŸš©END OF RESPONSE\n"
     ]
    }
   ],
   "source": [
    "query_resp = query_engine.query(\"What is flagship product of Colosscious\")\n",
    "\n",
    "print_resp(query_resp.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 19:52:36,318 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "âœ… RESPONSE:\n",
      "************************************************************\n",
      "\n",
      "PharmQuer is an international pharmacovigilance\n",
      "electronic system used in more than 80 countries for\n",
      "the collection and analysis of spontaneous case reports\n",
      "(adverse reactions to drugs). It is a free, web-based\n",
      "platform that allows users to report, review and\n",
      "analyze cases. The primary purpose of PharmQuer is to\n",
      "facilitate data sharing between regulatory agencies,\n",
      "pharmaceutical companies, academia, and other\n",
      "stakeholders in the field of pharmacovigilance.\n",
      "\n",
      "************************************************************\n",
      " ðŸš©END OF RESPONSE\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_chat_engine()\n",
    "query_resp = query_engine.query(\"What is Pharmquer?\")\n",
    "print_resp(query_resp.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load existing embeddings in ChromaDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: index_construction\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cb/80zl4p1j4557_30l5vq25k6h0000gn/T/ipykernel_34023/1229273192.py:1: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(llm=llm, embed_model=embedding_model, text_splitter=text_splitter,\n"
     ]
    }
   ],
   "source": [
    "service_context = ServiceContext.from_defaults(llm=llm, embed_model=embedding_model, text_splitter=text_splitter,\n",
    "    prompt_helper=prompt_helper, callback_manager=callback_manager)\n",
    "# load your index from stored vectors\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store, storage_context=storage_context, service_context=service_context\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a query engine\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Top 1 nodes:\n",
      "> Top 1 nodes:\n",
      "> [Node cb553733-838a-421b-89bf-c582fe90182a] [Similarity score: 0.37691508919720346] Welcome to Colosscious. \n",
      "We are the expert who spotlight-focus on providing the digital technolog...\n",
      "> [Node cb553733-838a-421b-89bf-c582fe90182a] [Similarity score: 0.37691508919720346] Welcome to Colosscious. \n",
      "We are the expert who spotlight-focus on providing the digital technolog...\n",
      "> [Node 5b2ae422-9c47-47b9-aad2-e97c95d22903] [Similarity score: 0.37691508919720346] Welcome to Colosscious. \n",
      "We are the expert who spotlight-focus on providing the digital technolog...\n",
      "> [Node 5b2ae422-9c47-47b9-aad2-e97c95d22903] [Similarity score: 0.37691508919720346] Welcome to Colosscious. \n",
      "We are the expert who spotlight-focus on providing the digital technolog...\n",
      "> Top 2 nodes:\n",
      "> [Node cb553733-838a-421b-89bf-c582fe90182a] [Similarity score:             0.376915] Welcome to Colosscious. \n",
      "We are the expert who spotlight-focus on providing the digital technolog...\n",
      "> [Node 5b2ae422-9c47-47b9-aad2-e97c95d22903] [Similarity score:             0.376915] Welcome to Colosscious. \n",
      "We are the expert who spotlight-focus on providing the digital technolog...\n",
      "> Top 2 nodes:\n",
      "> [Node cb553733-838a-421b-89bf-c582fe90182a] [Similarity score:             0.376915] Welcome to Colosscious. \n",
      "We are the expert who spotlight-focus on providing the digital technolog...\n",
      "> [Node 5b2ae422-9c47-47b9-aad2-e97c95d22903] [Similarity score:             0.376915] Welcome to Colosscious. \n",
      "We are the expert who spotlight-focus on providing the digital technolog...\n",
      "çœ‹é€™\n",
      "[NodeWithScore(node=TextNode(id_='cb553733-838a-421b-89bf-c582fe90182a', embedding=None, metadata={'file_path': 'test_docs/simple_txt_short_en/who_is_colosscious.txt', 'file_name': 'who_is_colosscious.txt', 'file_type': 'text/plain', 'file_size': 291, 'creation_date': '2024-01-15', 'last_modified_date': '2024-01-11', 'last_accessed_date': '2024-01-15'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='354e0ce3-b1e2-43c8-88c8-8a51de3e36d2', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': 'test_docs/simple_txt_short_en/who_is_colosscious.txt', 'file_name': 'who_is_colosscious.txt', 'file_type': 'text/plain', 'file_size': 291, 'creation_date': '2024-01-15', 'last_modified_date': '2024-01-11', 'last_accessed_date': '2024-01-15'}, hash='1901712403a8cf1475789046019020c0a0955a24b1710dcced84a0cc9b065bd3'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1f7abdb8-4dbb-4f9d-9398-f59fb630b862', node_type=<ObjectType.TEXT: '1'>, metadata={'file_path': 'test_docs/simple_txt_short_en/what_is_pharmquer.txt', 'file_name': 'what_is_pharmquer.txt', 'file_type': 'text/plain', 'file_size': 168, 'creation_date': '2024-02-07', 'last_modified_date': '2024-02-07', 'last_accessed_date': '2024-02-07'}, hash='bbe7fef3f7c062ebb8e6bcd403a94f94a46bc13de3171c63787f13df019229a1')}, text='Welcome to Colosscious. \\nWe are the expert who spotlight-focus on providing the digital technology to bio and pharmaceutical companies, engaging in boosting the performances of new drug developments, quality control, manufacturing processes, and reducing the costs and duration by Big Data.', start_char_idx=0, end_char_idx=290, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.37691508919720346)]\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2cb2d5960>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2cb2d5960>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Tue, 13 Feb 2024 01:02:49 GMT'), (b'Content-Length', b'600')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Tue, 13 Feb 2024 01:02:49 GMT'), (b'Content-Length', b'600')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 02:02:49,467 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.started\n",
      "close.complete\n",
      "close.complete\n",
      "âœ… RESPONSE:\n",
      "************************************************************\n",
      "\n",
      " Colosconscious is an expert entity that specializes in\n",
      "providing digital technology solutions to bio and\n",
      "pharmaceutical companies. Their focus areas include\n",
      "enhancing new drug development, improving quality\n",
      "control processes, optimizing manufacturing methods,\n",
      "and reducing costs and durations through the\n",
      "application of Big Data.\n",
      "\n",
      "************************************************************\n",
      " ðŸš©END OF RESPONSE\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is Colosscious?\")\n",
    "print_resp(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Top 1 nodes:\n",
      "> Top 1 nodes:\n",
      "> [Node cb553733-838a-421b-89bf-c582fe90182a] [Similarity score: 0.37691508919720346] Welcome to Colosscious. \n",
      "We are the expert who spotlight-focus on providing the digital technolog...\n",
      "> [Node cb553733-838a-421b-89bf-c582fe90182a] [Similarity score: 0.37691508919720346] Welcome to Colosscious. \n",
      "We are the expert who spotlight-focus on providing the digital technolog...\n",
      "> [Node 5b2ae422-9c47-47b9-aad2-e97c95d22903] [Similarity score: 0.37691508919720346] Welcome to Colosscious. \n",
      "We are the expert who spotlight-focus on providing the digital technolog...\n",
      "> [Node 5b2ae422-9c47-47b9-aad2-e97c95d22903] [Similarity score: 0.37691508919720346] Welcome to Colosscious. \n",
      "We are the expert who spotlight-focus on providing the digital technolog...\n",
      "> Top 2 nodes:\n",
      "> [Node cb553733-838a-421b-89bf-c582fe90182a] [Similarity score:             0.376915] Welcome to Colosscious. \n",
      "We are the expert who spotlight-focus on providing the digital technolog...\n",
      "> [Node 5b2ae422-9c47-47b9-aad2-e97c95d22903] [Similarity score:             0.376915] Welcome to Colosscious. \n",
      "We are the expert who spotlight-focus on providing the digital technolog...\n",
      "> Top 2 nodes:\n",
      "> [Node cb553733-838a-421b-89bf-c582fe90182a] [Similarity score:             0.376915] Welcome to Colosscious. \n",
      "We are the expert who spotlight-focus on providing the digital technolog...\n",
      "> [Node 5b2ae422-9c47-47b9-aad2-e97c95d22903] [Similarity score:             0.376915] Welcome to Colosscious. \n",
      "We are the expert who spotlight-focus on providing the digital technolog...\n",
      "çœ‹é€™\n",
      "[NodeWithScore(node=TextNode(id_='cb553733-838a-421b-89bf-c582fe90182a', embedding=None, metadata={'file_path': 'test_docs/simple_txt_short_en/who_is_colosscious.txt', 'file_name': 'who_is_colosscious.txt', 'file_type': 'text/plain', 'file_size': 291, 'creation_date': '2024-01-15', 'last_modified_date': '2024-01-11', 'last_accessed_date': '2024-01-15'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='354e0ce3-b1e2-43c8-88c8-8a51de3e36d2', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': 'test_docs/simple_txt_short_en/who_is_colosscious.txt', 'file_name': 'who_is_colosscious.txt', 'file_type': 'text/plain', 'file_size': 291, 'creation_date': '2024-01-15', 'last_modified_date': '2024-01-11', 'last_accessed_date': '2024-01-15'}, hash='1901712403a8cf1475789046019020c0a0955a24b1710dcced84a0cc9b065bd3'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1f7abdb8-4dbb-4f9d-9398-f59fb630b862', node_type=<ObjectType.TEXT: '1'>, metadata={'file_path': 'test_docs/simple_txt_short_en/what_is_pharmquer.txt', 'file_name': 'what_is_pharmquer.txt', 'file_type': 'text/plain', 'file_size': 168, 'creation_date': '2024-02-07', 'last_modified_date': '2024-02-07', 'last_accessed_date': '2024-02-07'}, hash='bbe7fef3f7c062ebb8e6bcd403a94f94a46bc13de3171c63787f13df019229a1')}, text='Welcome to Colosscious. \\nWe are the expert who spotlight-focus on providing the digital technology to bio and pharmaceutical companies, engaging in boosting the performances of new drug developments, quality control, manufacturing processes, and reducing the costs and duration by Big Data.', start_char_idx=0, end_char_idx=290, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.37691508919720346)]\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2cb2b8eb0>\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2cb2b8eb0>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Tue, 13 Feb 2024 01:02:58 GMT'), (b'Content-Length', b'562')])\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Tue, 13 Feb 2024 01:02:58 GMT'), (b'Content-Length', b'562')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 02:02:58,931 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.started\n",
      "close.complete\n",
      "close.complete\n",
      "âœ… RESPONSE:\n",
      "************************************************************\n",
      "\n",
      " Coloscius is an expert organization that specializes\n",
      "in providing digital technology solutions to bio and\n",
      "pharmaceutical companies. Their focus includes\n",
      "enhancing new drug development, ensuring quality\n",
      "control, optimizing manufacturing processes, and\n",
      "reducing costs and duration through the application of\n",
      "Big Data.\n",
      "\n",
      "************************************************************\n",
      " ðŸš©END OF RESPONSE\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is Colosscious?\")\n",
    "print_resp(response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use llama_index_object_array_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'x1': 97.98219999874924,\n",
       "  'x2': 99.84941752810117,\n",
       "  'x3': 100.9727776594234,\n",
       "  'y': 360.87650920565545},\n",
       " {'x1': 101.00077953260389,\n",
       "  'x2': 99.87874921228179,\n",
       "  'x3': 99.35642250227457,\n",
       "  'y': 361.50488035486944}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview: demo data\n",
    "simple_ols[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ObjectArrayReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   x1      50 non-null     float64\n",
      " 1   x2      50 non-null     float64\n",
      " 2   x3      50 non-null     float64\n",
      " 3   y       50 non-null     float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 1.7 KB\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.readers.base import Document\n",
    "object_arrays:list[Document] = loader.load_data(file=simple_ols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(simple_ols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='7caf7ec5-3892-4b9c-9195-a5b0a1795ee4', embedding=None, metadata={'columns': \"['x1', 'x2', 'x3', 'y']\", 'schema': 'None', 'shape': '(50, 4)'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='97.98219999874924, 99.84941752810117, 100.9727776594234, 360.87650920565545\\n101.00077953260389, 99.87874921228179, 99.35642250227457, 361.50488035486944\\n98.5109626677227, 100.7485502397903, 99.46465098250788, 359.8117609861218\\n100.77335929310553, 100.03722922045552, 99.86657209922947, 362.2336960397953\\n100.97359840386007, 99.1724799721807, 100.16093297144785, 362.1391160315852\\n100.18799255929102, 100.55900119891184, 100.61532849440285, 363.29752977180965\\n100.9157547652626, 98.61649241995889, 99.06726035297895, 359.7975894964005\\n101.04615952660859, 102.00920930524853, 100.16419028246959, 364.8003752715575\\n99.46321248760913, 100.23898461781165, 100.4603474082993, 361.9810830871964\\n101.01997365057879, 100.70311893925478, 100.35193718659701, 363.88982333927027\\n100.13690655914681, 100.07882115404048, 98.55349011863521, 359.46137480234387\\n101.06426034086174, 100.39468013724496, 99.59524654141205, 362.4291116312047\\n98.37827347228104, 103.02974783668428, 100.1611399406794, 362.8735393636648\\n99.97507192990182, 98.90754655604644, 99.80434032022505, 360.25326008000667\\n100.39532804084602, 100.00783015782618, 98.84412853695146, 360.1443934124746\\n100.53538350964381, 101.45593826545792, 101.35656192129933, 365.686428125867\\n101.82462124282185, 100.60168747124192, 101.17271531836492, 365.98868463340847\\n100.20083842899689, 100.08207154841824, 99.58637885148526, 361.20837231254296\\n101.21055853157635, 100.14337012301043, 97.83946914592629, 359.5083658057684\\n99.18284850767726, 99.36415064348877, 99.44933313879001, 359.2461732873584\\n98.68076906156287, 99.88606328063753, 100.63302113481906, 361.1047253879728\\n100.69262845160499, 100.95667625950557, 100.42976056344008, 363.89692658755564\\n99.28259711401759, 99.70388277366841, 101.68434722375862, 363.2876025473195\\n100.06352462146366, 98.88111045420715, 98.17662400762073, 357.68289832611293\\n99.30093777662633, 99.66957998231912, 101.04827928253668, 362.24405534917537\\n101.80808125496162, 98.90879253371892, 100.43144827373477, 363.22961316755584\\n100.87937300919184, 100.21857314642527, 98.7095417586287, 360.6345955200315\\n101.26476906248293, 100.78711425646654, 100.29822225418964, 364.14048570001194\\n99.91296978569375, 99.81832037463671, 100.93755148875996, 362.85330879179776\\n98.33923043666618, 101.41609851401992, 100.9069226929846, 362.5750535271962\\n99.16537289151567, 101.53101959448773, 98.68726411895874, 359.9607243551743\\n99.03719843850321, 101.11878894468508, 100.96547923761082, 363.1452988224573\\n99.43406666585818, 100.91739344461386, 99.36206117770445, 360.78473992459374\\n99.68590044334066, 99.48627235799435, 99.56930464452118, 360.089118523317\\n97.32232213736515, 99.97594783847929, 100.69691843112757, 359.8391638384025\\n99.39074229940556, 99.93236851645756, 98.2362250018063, 358.01656116479893\\n100.77590520414071, 99.69003697728576, 98.90965598576909, 360.3683307126241\\n99.68679150345386, 99.02927646327905, 101.76626758973612, 363.239031940659\\n100.64548154386631, 99.20184240211881, 100.01344022902087, 361.5760580247661\\n98.99353686788966, 99.96912376997722, 101.61919061254812, 363.11424644961215\\n99.61923454090937, 99.106406018837, 100.84958819151115, 361.7497627252443\\n99.07093312420517, 100.95979226903094, 99.95112469407546, 361.39111973582743\\n100.07233850453227, 99.7129946461946, 101.44068386026443, 363.74407241841885\\n99.72656237514776, 98.72754826499948, 99.97952513372913, 360.1084405895639\\n99.52984537048624, 102.18311836300242, 98.52851110733191, 360.68518093107895\\n101.14589750687492, 101.45663623211762, 100.70204076103222, 365.2772452093873\\n100.69113884387745, 100.5140731983062, 98.73201138024642, 360.73859881401285\\n100.97373793175905, 99.21840952279409, 98.11881715092599, 358.8678844756544\\n103.14715709169663, 98.60042261009588, 100.7938715049434, 364.9675528117923\\n100.6433422264419, 100.72347518969544, 99.54248360001975, 362.1927963663157', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_arrays[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cb/80zl4p1j4557_30l5vq25k6h0000gn/T/ipykernel_35003/3300894910.py:1: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(llm=llm, embed_model=embedding_model, callback_manager=callback_manager)\n",
      "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2225 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Adding chunk: 97.98219999874924, 99.84941752810117, 100.97277...\n",
      "> Adding chunk: 98.90754655604644, 99.80434032022505, 360.25326...\n",
      "> Adding chunk: 26476906248293, 100.78711425646654, 100.2982222...\n",
      "> Adding chunk: 100.84958819151115, 361.7497627252443\n",
      "99.070933...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 42.52it/s]\n",
      "Generating embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: index_construction\n",
      "    |_node_parsing ->  0.026223 seconds\n",
      "      |_chunking ->  0.02075 seconds\n",
      "    |_embedding ->  0.597961 seconds\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "service_context = ServiceContext.from_defaults(llm=llm, embed_model=embedding_model, callback_manager=callback_manager)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents=object_arrays, service_context=service_context,  storage_context=storage_context, show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(simple_ols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='7caf7ec5-3892-4b9c-9195-a5b0a1795ee4', embedding=None, metadata={'columns': \"['x1', 'x2', 'x3', 'y']\", 'schema': 'None', 'shape': '(50, 4)'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='97.98219999874924, 99.84941752810117, 100.9727776594234, 360.87650920565545\\n101.00077953260389, 99.87874921228179, 99.35642250227457, 361.50488035486944\\n98.5109626677227, 100.7485502397903, 99.46465098250788, 359.8117609861218\\n100.77335929310553, 100.03722922045552, 99.86657209922947, 362.2336960397953\\n100.97359840386007, 99.1724799721807, 100.16093297144785, 362.1391160315852\\n100.18799255929102, 100.55900119891184, 100.61532849440285, 363.29752977180965\\n100.9157547652626, 98.61649241995889, 99.06726035297895, 359.7975894964005\\n101.04615952660859, 102.00920930524853, 100.16419028246959, 364.8003752715575\\n99.46321248760913, 100.23898461781165, 100.4603474082993, 361.9810830871964\\n101.01997365057879, 100.70311893925478, 100.35193718659701, 363.88982333927027\\n100.13690655914681, 100.07882115404048, 98.55349011863521, 359.46137480234387\\n101.06426034086174, 100.39468013724496, 99.59524654141205, 362.4291116312047\\n98.37827347228104, 103.02974783668428, 100.1611399406794, 362.8735393636648\\n99.97507192990182, 98.90754655604644, 99.80434032022505, 360.25326008000667\\n100.39532804084602, 100.00783015782618, 98.84412853695146, 360.1443934124746\\n100.53538350964381, 101.45593826545792, 101.35656192129933, 365.686428125867\\n101.82462124282185, 100.60168747124192, 101.17271531836492, 365.98868463340847\\n100.20083842899689, 100.08207154841824, 99.58637885148526, 361.20837231254296\\n101.21055853157635, 100.14337012301043, 97.83946914592629, 359.5083658057684\\n99.18284850767726, 99.36415064348877, 99.44933313879001, 359.2461732873584\\n98.68076906156287, 99.88606328063753, 100.63302113481906, 361.1047253879728\\n100.69262845160499, 100.95667625950557, 100.42976056344008, 363.89692658755564\\n99.28259711401759, 99.70388277366841, 101.68434722375862, 363.2876025473195\\n100.06352462146366, 98.88111045420715, 98.17662400762073, 357.68289832611293\\n99.30093777662633, 99.66957998231912, 101.04827928253668, 362.24405534917537\\n101.80808125496162, 98.90879253371892, 100.43144827373477, 363.22961316755584\\n100.87937300919184, 100.21857314642527, 98.7095417586287, 360.6345955200315\\n101.26476906248293, 100.78711425646654, 100.29822225418964, 364.14048570001194\\n99.91296978569375, 99.81832037463671, 100.93755148875996, 362.85330879179776\\n98.33923043666618, 101.41609851401992, 100.9069226929846, 362.5750535271962\\n99.16537289151567, 101.53101959448773, 98.68726411895874, 359.9607243551743\\n99.03719843850321, 101.11878894468508, 100.96547923761082, 363.1452988224573\\n99.43406666585818, 100.91739344461386, 99.36206117770445, 360.78473992459374\\n99.68590044334066, 99.48627235799435, 99.56930464452118, 360.089118523317\\n97.32232213736515, 99.97594783847929, 100.69691843112757, 359.8391638384025\\n99.39074229940556, 99.93236851645756, 98.2362250018063, 358.01656116479893\\n100.77590520414071, 99.69003697728576, 98.90965598576909, 360.3683307126241\\n99.68679150345386, 99.02927646327905, 101.76626758973612, 363.239031940659\\n100.64548154386631, 99.20184240211881, 100.01344022902087, 361.5760580247661\\n98.99353686788966, 99.96912376997722, 101.61919061254812, 363.11424644961215\\n99.61923454090937, 99.106406018837, 100.84958819151115, 361.7497627252443\\n99.07093312420517, 100.95979226903094, 99.95112469407546, 361.39111973582743\\n100.07233850453227, 99.7129946461946, 101.44068386026443, 363.74407241841885\\n99.72656237514776, 98.72754826499948, 99.97952513372913, 360.1084405895639\\n99.52984537048624, 102.18311836300242, 98.52851110733191, 360.68518093107895\\n101.14589750687492, 101.45663623211762, 100.70204076103222, 365.2772452093873\\n100.69113884387745, 100.5140731983062, 98.73201138024642, 360.73859881401285\\n100.97373793175905, 99.21840952279409, 98.11881715092599, 358.8678844756544\\n103.14715709169663, 98.60042261009588, 100.7938715049434, 364.9675528117923\\n100.6433422264419, 100.72347518969544, 99.54248360001975, 362.1927963663157', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a query engine\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Top 1 nodes:\n",
      "> [Node 021d374e-1c7e-4935-823f-e9ee662007e4] [Similarity score: 0.23697712076054578] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> [Node ec5b09f1-bc2b-4225-99d8-4bed978ccabd] [Similarity score: 0.23697712076054578] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> Top 2 nodes:\n",
      "> [Node 021d374e-1c7e-4935-823f-e9ee662007e4] [Similarity score:             0.236977] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> [Node ec5b09f1-bc2b-4225-99d8-4bed978ccabd] [Similarity score:             0.236977] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2d1dfee00>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Tue, 13 Feb 2024 01:06:11 GMT'), (b'Content-Length', b'456')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 02:06:11,815 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "âœ… RESPONSE:\n",
      "************************************************************\n",
      "\n",
      " The provided context consists of 50 rows, each\n",
      "containing 4 columns. Therefore, there are a total of\n",
      "50 rows multiplied by 4 columns, resulting in a total\n",
      "of 200 values in the dataset.\n",
      "\n",
      "************************************************************\n",
      " ðŸš©END OF RESPONSE\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"How many values with in the dataset?\")\n",
    "print_resp(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Top 1 nodes:\n",
      "> [Node 021d374e-1c7e-4935-823f-e9ee662007e4] [Similarity score: 0.23697712076054578] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> [Node ec5b09f1-bc2b-4225-99d8-4bed978ccabd] [Similarity score: 0.23697712076054578] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> Top 2 nodes:\n",
      "> [Node 021d374e-1c7e-4935-823f-e9ee662007e4] [Similarity score:             0.236977] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> [Node ec5b09f1-bc2b-4225-99d8-4bed978ccabd] [Similarity score:             0.236977] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2d1e9d2a0>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Tue, 13 Feb 2024 01:06:13 GMT'), (b'Content-Length', b'382')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 02:06:13,655 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "âœ… RESPONSE:\n",
      "************************************************************\n",
      "\n",
      " The provided context consists of 13 rows, each row\n",
      "having 4 columns. Therefore, the total number of values\n",
      "in the dataset is 13 x 4 = 52.\n",
      "\n",
      "************************************************************\n",
      " ðŸš©END OF RESPONSE\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"How many values with in the dataset?\")\n",
    "print_resp(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 15:13:24,979 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "âœ… RESPONSE:\n",
      "************************************************************\n",
      "\n",
      " There are three columns' names that start with 'x',\n",
      "which are 'x1', 'x2', and 'x3'.\n",
      "\n",
      "************************************************************\n",
      " ðŸš©END OF RESPONSE\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"How many columns' name starts with 'x'?\")\n",
    "print_resp(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 15:21:03,508 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "âœ… RESPONSE:\n",
      "************************************************************\n",
      "\n",
      " To find the average of column 'x1', we need to sum all\n",
      "the values in column 'x1' and then divide by the total\n",
      "number of rows (50). Here are all the values in column\n",
      "'x1':  99.07093312420517, 100.84958819151115,\n",
      "99.72656237514776, ... , 100.97373793175905  Adding all\n",
      "the values gives us:  99.07093312420517 +\n",
      "100.84958819151115 + ... + 100.97373793175905 = (sum of\n",
      "all x1 values)  Now, we need to divide the sum by the\n",
      "total number of rows, which is 50:  (sum of all x1\n",
      "values) / 50 = average of column 'x1'  Without\n",
      "calculating the exact sum, we can see that the average\n",
      "value lies between 98.73 (lowest value) and 100.97\n",
      "(highest value). However, without performing the actual\n",
      "calculation, we cannot provide an exact numerical\n",
      "answer for the average of column 'x1'.  Please note\n",
      "that providing the exact average would require further\n",
      "calculations that go beyond the scope of this AI model.\n",
      "\n",
      "************************************************************\n",
      " ðŸš©END OF RESPONSE\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is the average of column 'x1'?\")\n",
    "print_resp(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97.982200</td>\n",
       "      <td>99.849418</td>\n",
       "      <td>100.972778</td>\n",
       "      <td>360.876509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.000780</td>\n",
       "      <td>99.878749</td>\n",
       "      <td>99.356423</td>\n",
       "      <td>361.504880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98.510963</td>\n",
       "      <td>100.748550</td>\n",
       "      <td>99.464651</td>\n",
       "      <td>359.811761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.773359</td>\n",
       "      <td>100.037229</td>\n",
       "      <td>99.866572</td>\n",
       "      <td>362.233696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.973598</td>\n",
       "      <td>99.172480</td>\n",
       "      <td>100.160933</td>\n",
       "      <td>362.139116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1          x2          x3           y\n",
       "0   97.982200   99.849418  100.972778  360.876509\n",
       "1  101.000780   99.878749   99.356423  361.504880\n",
       "2   98.510963  100.748550   99.464651  359.811761\n",
       "3  100.773359  100.037229   99.866572  362.233696\n",
       "4  100.973598   99.172480  100.160933  362.139116"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     97.982200\n",
      "1    101.000780\n",
      "2     98.510963\n",
      "3    100.773359\n",
      "4    100.973598\n",
      "Name: x1, dtype: float64\n",
      "Mean=  100.07520939069373\n"
     ]
    }
   ],
   "source": [
    "print(df['x1'][:5])\n",
    "print('Mean= ', df['x1'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub Question Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Top 1 nodes:\n",
      "> [Node 1d4d4017-e547-4063-8f27-98eca3937345] [Similarity score: 0.21449468596442905] Welcome to Colosscious. \n",
      "We are the expert who spotlight-focus on providing the digital technolog...\n",
      "> [Node 7e1706e8-8321-409c-b1fd-72891a749953] [Similarity score: 0.21449468596442905] Welcome to Colosscious. \n",
      "We are the expert who spotlight-focus on providing the digital technolog...\n",
      "> Top 2 nodes:\n",
      "> [Node 1d4d4017-e547-4063-8f27-98eca3937345] [Similarity score:             0.214495] Welcome to Colosscious. \n",
      "We are the expert who spotlight-focus on providing the digital technolog...\n",
      "> [Node 7e1706e8-8321-409c-b1fd-72891a749953] [Similarity score:             0.214495] Welcome to Colosscious. \n",
      "We are the expert who spotlight-focus on providing the digital technolog...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2d1ee55d0>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Tue, 13 Feb 2024 01:06:31 GMT'), (b'Content-Length', b'562')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 02:06:31,440 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "âœ… RESPONSE:\n",
      "************************************************************\n",
      "\n",
      " In the provided context, there is no mention of a\n",
      "dataset. The text describes Colosscious as an expert in\n",
      "digital technology solutions for bio and pharmaceutical\n",
      "companies, focusing on improving drug development,\n",
      "quality control, manufacturing processes, and cost\n",
      "reduction through Big Data.\n",
      "\n",
      "************************************************************\n",
      " ðŸš©END OF RESPONSE\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What about the dataset?\"\n",
    ")\n",
    "print_resp(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.query_engine import SubQuestionQueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=query_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"summary_tool\",\n",
    "            description=f\"Return the shape of the dataset and the basic summary of the dataset, such as mean, range, stddev of each columns.\",\n",
    "        ),\n",
    "    ),\n",
    "] \n",
    "\n",
    "query_engine = SubQuestionQueryEngine.from_defaults(\n",
    "    query_engine_tools=query_engine_tools,\n",
    "    service_context=service_context,\n",
    "    verbose=True,\n",
    "    use_async=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2d80d6260>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Tue, 13 Feb 2024 01:07:39 GMT'), (b'Content-Length', b'622')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 02:07:39,756 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "Generated 2 sub questions.\n",
      "\u001b[1;3;38;2;237;90;200m[summary_tool] Q: What is the shape of the dataset\n",
      "\u001b[0m> Top 1 nodes:\n",
      "> [Node 021d374e-1c7e-4935-823f-e9ee662007e4] [Similarity score: 0.3079660874249297] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> [Node ec5b09f1-bc2b-4225-99d8-4bed978ccabd] [Similarity score: 0.3079660874249297] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> Top 2 nodes:\n",
      "> [Node 021d374e-1c7e-4935-823f-e9ee662007e4] [Similarity score:             0.307966] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> [Node ec5b09f1-bc2b-4225-99d8-4bed978ccabd] [Similarity score:             0.307966] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2d82f56c0>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Tue, 13 Feb 2024 01:07:44 GMT'), (b'Content-Length', b'436')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 02:07:44,691 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "\u001b[1;3;38;2;237;90;200m[summary_tool] A:  The given data represents 50 observations, each with four features or columns. Therefore, the shape of the dataset can be described as having 50 rows and 4 columns.\n",
      "\u001b[0m\u001b[1;3;38;2;90;149;237m[summary_tool] Q: What are the mean, range, and stddev of each column in the dataset\n",
      "\u001b[0m> Top 1 nodes:\n",
      "> [Node 021d374e-1c7e-4935-823f-e9ee662007e4] [Similarity score: 0.27269000508346425] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> [Node ec5b09f1-bc2b-4225-99d8-4bed978ccabd] [Similarity score: 0.27269000508346425] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> Top 2 nodes:\n",
      "> [Node 021d374e-1c7e-4935-823f-e9ee662007e4] [Similarity score:             0.27269] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> [Node ec5b09f1-bc2b-4225-99d8-4bed978ccabd] [Similarity score:             0.27269] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2d82f4070>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Tue, 13 Feb 2024 01:08:14 GMT'), (b'Transfer-Encoding', b'chunked')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 02:08:14,751 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "\u001b[1;3;38;2;90;149;237m[summary_tool] A:  To calculate the mean, range, and standard deviation for each column in the given dataset, we need to perform some numerical calculations using the values present in the dataset. Here's how we can find them:\n",
      "\n",
      "1. Mean: For each column, sum up all the corresponding values and then divide by the total number of observations (number of rows).\n",
      "\n",
      "2. Range: Find the difference between the maximum value and minimum value for a given column.\n",
      "\n",
      "3. Standard deviation: First, calculate the variance (average of squared differences from the mean) for each column, then take the square root of the variance to find the standard deviation.\n",
      "\n",
      "Let's compute these values for the columns in the dataset provided:\n",
      "\n",
      "Column 'x1':\n",
      "- Mean: Sum of all 'x1' values / Total number of rows = (100.84958819 + 99.07093312 + ... + 103.14715709) / 50\n",
      "- Range: Maximum 'x1' value - Minimum 'x1' value = max(103.14715709, 100.84958819) - min(99.07093312, 98.60042261)\n",
      "- Standard deviation: Not calculated here, but it can be computed using the variance and square root.\n",
      "\n",
      "Column 'x2':\n",
      "- Mean: Sum of all 'x2' values / Total number of rows = (361.74976273 + 100.95979227 + ... + 364.96755281) / 50\n",
      "- Range: Maximum 'x2' value - Minimum 'x2' value = max(364.96755281, 361.74976273) - min(100.95979227, 358.86788448)\n",
      "- Standard deviation: Not calculated here, but it can be computed using the variance and square root.\n",
      "\n",
      "Column 'x3':\n",
      "- Mean: Sum of all 'x3' values / Total number of rows = (99.95112469 + 98.72754826 + ... + 98.52851111) / 50\n",
      "- Range: Maximum 'x3' value - Minimum 'x3' value = max(98.52851111, 99.95112469) - min(98.72754826, 97.26562376)\n",
      "- Standard deviation: Not calculated here, but it can be computed using the variance and square root.\n",
      "\n",
      "Column 'y':\n",
      "- Mean: Sum of all 'y' values / Total number of rows = (361.39111974 + 360.3911, 363.74407242 + ... + 365.27724521) / 50\n",
      "- Range: Maximum 'y' value - Minimum 'y' value = max(365.27724521, 358.86788448) - min(360.10844059, 360.68518093)\n",
      "- Standard deviation: Not calculated here, but it can be computed using the variance and square root.\n",
      "\u001b[0mload_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2d82f5b10>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Tue, 13 Feb 2024 01:08:23 GMT'), (b'Content-Length', b'1002')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 02:08:23,226 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "âœ… RESPONSE:\n",
      "************************************************************\n",
      "\n",
      " The given dataset consists of 50 observations with\n",
      "each observation having four features or columns\n",
      "labeled as 'x1', 'x2', 'x3', and 'y'. To calculate\n",
      "statistical measures such as mean, range, and standard\n",
      "deviation for each column, we need to perform numerical\n",
      "calculations using the values present in the dataset.\n",
      "These calculations involve finding the sum of all\n",
      "values for a given column and dividing it by the total\n",
      "number of observations (rows) to find the mean. The\n",
      "range is found by subtracting the minimum value from\n",
      "the maximum value for a given column, while standard\n",
      "deviation can be computed using the variance and square\n",
      "root. These calculations have been outlined in detail\n",
      "for each column in the dataset provided.\n",
      "\n",
      "************************************************************\n",
      " ðŸš©END OF RESPONSE\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "   \"What about the dataset?\"\n",
    ")\n",
    "print_resp(response.response )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
