{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'VectorStoreIndex' from 'llama_index' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtextwrap\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VectorStoreIndex, SimpleDirectoryReader, StorageContext, get_response_synthesizer, PromptHelper\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext_splitter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceSplitter\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrievers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VectorIndexRetriever\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'VectorStoreIndex' from 'llama_index' (unknown location)"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import importlib\n",
    "import textwrap\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, StorageContext, get_response_synthesizer, PromptHelper\n",
    "from llama_index.text_splitter import SentenceSplitter\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.vector_stores import ChromaVectorStore\n",
    "from llamaindex_object_array_reader.dataset import simple_ols # import a simple dataset \n",
    "from llama_index.llms import HuggingFaceLLM\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import BitsAndBytesConfig\n",
    "from llama_index.llms import Ollama\n",
    "from llama_index import ServiceContext, set_global_tokenizer\n",
    "# from langchain.embeddings import HuggingFaceEmbedding, HuggingFaceInstructEmbeddings\n",
    "from llama_index.embeddings import HuggingFaceEmbedding\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from argparse import Namespace\n",
    "from chromadb import Collection, PersistentClient\n",
    "from dotenv import load_dotenv\n",
    "from llamaindex_object_array_reader import ObjectArrayReader\n",
    "from llama_index.callbacks import CallbackManager, LlamaDebugHandler\n",
    "import nest_asyncio\n",
    "\n",
    "# 允许嵌套事件循环\n",
    "nest_asyncio.apply()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from llamaindex_object_array_reader._logging import logger\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "log = logger\n",
    "log.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
    "callback_manager = CallbackManager([llama_debug])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obsolete\n",
    "# if os.path.exists('my_cred.py'):\n",
    "#     my_cred = importlib.import_module('my_cred')\n",
    "#     os.environ['OPENAI_API_KEY'] = my_cred.OPENAI_API_KEY\n",
    "# else:\n",
    "#     # Set your OPENAI API Key\n",
    "#     os.environ['OPENAI_API_KEY'] = \"vy-...cH5N\"\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
    "HF_TOKEN = os.environ['HF_TOKEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_resp(msg, max_len:int=55):\n",
    "    \"\"\"将文本分割为每行最大长度的子字符串\n",
    "    \"\"\"\n",
    "    divider: str = '\\n'+ '*'*60+'\\n'\n",
    "    msg = textwrap.fill(msg, width=max_len)\n",
    "    print(f\"\"\"\\u2705 RESPONSE:{divider}\\n{msg}\\n{divider} \\U0001F6A9END OF RESPONSE\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models:Namespace = Namespace(\n",
    "    BERT_BASE_CHINESE=\"bert-base-chinese\",\n",
    "    LLAMA2_CHINESE_7B_CHAT=\"FlagAlpha/Llama2-Chinese-7b-Chat\", #18G needed\n",
    "    LLAMA2_7B_CHAT_HF=\"meta-llama/Llama-2-7b-chat-hf\", #18G needed\n",
    "    BLOOM_560M=\"bigscience/bloom-560m\", #18G needed\n",
    "    BLOOMZ_560M=\"bigscience/bloomz-560m\", #18G needed\n",
    "    GPT2=\"GPT2\", #18G needed\n",
    "    ALL_MPNET_BASE_V2=\"sentence-transformers/all-mpnet-base-v2\", #18G needed\n",
    "    MISTRAL_7B_INSTRUCT_V0_1=\"mistralai/Mistral-7B-Instruct-v0.1\", #18G needed\n",
    "    STARLING_LM_7B=\"berkeley-nest/Starling-LM-7B-alpha\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the check point\n",
    "check_point:str = models.ALL_MPNET_BASE_V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new HTTPS connection (1): huggingface.co:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://huggingface.co:443 \"HEAD /sentence-transformers/all-mpnet-base-v2/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(check_point)\n",
    "set_global_tokenizer(tokenizer)\n",
    "\n",
    "# Alternatively, using a local LLM\n",
    "USE_LOCAL:bool = True\n",
    "if USE_LOCAL:\n",
    "    # llm = Ollama(model=\"llama2-chinese\")\n",
    "    # llm = Ollama(model=\"starling-lm:7b-alpha-q3_K_M\")\n",
    "    llm = Ollama(model=\"mistral\")\n",
    "    \n",
    "else: \n",
    "    llm = HuggingFaceLLM(\n",
    "        model_name=check_point,\n",
    "        tokenizer_name=check_point,\n",
    "        context_window=512,\n",
    "        model_kwargs={\n",
    "            # 'torch_dtype':torch.float16,\n",
    "            \"token\": HF_TOKEN,\n",
    "            'load_in_8bit':False, #No, the bitsandbytes library only works on CUDA GPU. So it must set to 'False' as running on mac os. \n",
    "            'offload_folder':\"offload_folder\",\n",
    "            'offload_state_dict':True,\n",
    "            'is_decoder': True if check_point==models.BERT_BASE_CHINESE else None,\n",
    "            },\n",
    "        tokenizer_kwargs={\n",
    "            \"token\": HF_TOKEN,\n",
    "            \"return_tensors\":'pt',},\n",
    "        device_map=\"auto\" if check_point!=models.BERT_BASE_CHINESE else \"mps\", \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://huggingface.co:443 \"HEAD /sentence-transformers/all-mpnet-base-v2/resolve/main/config.json HTTP/1.1\" 200 0\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbedding(\n",
    "    model_name=check_point,\n",
    "    tokenizer=tokenizer,\n",
    "    cache_folder=\"cache_folder\",\n",
    "    max_length=512,\n",
    "    device=\"mps\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = SentenceSplitter(chunk_size=512, chunk_overlap=64)\n",
    "prompt_helper = PromptHelper(\n",
    "    context_window=512,\n",
    "    num_output=256,\n",
    "    chunk_overlap_ratio=0.1,\n",
    "    chunk_size_limit=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> [SimpleDirectoryReader] Total files added: 3\n"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(\"test_docs/simple_txt_short_en\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Adding chunk: You can do data integration, management, analys...\n",
      "> Adding chunk: Colosscious' flagship product, Pharmquer, is an...\n",
      "> Adding chunk: Welcome to Colosscious. \n",
      "We are the expert who ...\n",
      "Total nodes: 3\n",
      "Node ID: 1b90da42-2951-4f96-b2a8-6ee9547b1618\n",
      "Text: You can do data integration, management, analysis and composing\n",
      "reports and dashboards with Pharmquer, and then automatize all your\n",
      "works.\n",
      "---\n",
      "Node ID: 038bfbf8-77c4-4e82-9bf9-1706442077e2\n",
      "Text: Colosscious' flagship product, Pharmquer, is an enterprise level\n",
      "software of manufacturing and business intelligence, which is\n",
      "architected especially for the industry.\n",
      "---\n",
      "Node ID: 49a00622-84ed-4f52-89c5-f6a4856cdea5\n",
      "Text: Welcome to Colosscious.  We are the expert who spotlight-focus\n",
      "on providing the digital technology to bio and pharmaceutical\n",
      "companies, engaging in boosting the performances of new drug\n",
      "developments, quality control, manufacturing processes, and reducing\n",
      "the costs and duration by Big Data.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Assuming documents have already been loaded\n",
    "# Initialize the parser\n",
    "parser = SimpleNodeParser.from_defaults(chunk_size=512, chunk_overlap=20)\n",
    "# Parse documents into nodes\n",
    "nodes = parser.get_nodes_from_documents(documents)\n",
    "print('Total nodes:', len(nodes))\n",
    "for _, n in enumerate(nodes):\n",
    "    print(n)\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:48:51,212 - chromadb.telemetry.product.posthog - \u001b[32;20mINFO\u001b[0m - (posthog.py:20) - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "Starting component System\n",
      "Starting component Posthog\n",
      "Starting component OpenTelemetryClient\n",
      "Starting component SimpleAssignmentPolicy\n",
      "Starting component SqliteDB\n",
      "Starting component LocalSegmentManager\n",
      "Starting component SegmentAPI\n"
     ]
    }
   ],
   "source": [
    "V_DB_NAME = \"chromadb\"\n",
    "chroma_client = PersistentClient(V_DB_NAME)\n",
    "COLLECTION_NAME:str = 'test'\n",
    "chroma_collection:Collection = chroma_client.get_or_create_collection(COLLECTION_NAME)\n",
    "vector_store = ChromaVectorStore(chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new HTTPS connection (1): app.posthog.com:443\n",
      "https://app.posthog.com:443 \"POST /batch/ HTTP/1.1\" 200 None\n"
     ]
    }
   ],
   "source": [
    "for n in nodes:\n",
    "    print(storage_context.docstore.document_exists(n.id_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and store new embeddings to ChromaDB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Generating embeddings: 100%|██████████| 3/3 [00:00<00:00,  5.29it/s]\n",
      "2024-02-07 22:47:49,898 - chromadb.segment.impl.vector.local_persistent_hnsw - \u001b[33;20mWARNING\u001b[0m - (local_persistent_hnsw.py:271) - Add of existing embedding ID: dc0f865e-90c8-42b0-9239-19625ebcef35 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: dc0f865e-90c8-42b0-9239-19625ebcef35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 22:47:49,898 - chromadb.segment.impl.vector.local_persistent_hnsw - \u001b[33;20mWARNING\u001b[0m - (local_persistent_hnsw.py:271) - Add of existing embedding ID: 1f7abdb8-4dbb-4f9d-9398-f59fb630b862 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: 1f7abdb8-4dbb-4f9d-9398-f59fb630b862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 22:47:49,899 - chromadb.segment.impl.vector.local_persistent_hnsw - \u001b[33;20mWARNING\u001b[0m - (local_persistent_hnsw.py:271) - Add of existing embedding ID: cb553733-838a-421b-89bf-c582fe90182a \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: cb553733-838a-421b-89bf-c582fe90182a\n"
     ]
    }
   ],
   "source": [
    "storage_context.docstore.add_documents(nodes)\n",
    "\n",
    "service_context = ServiceContext.from_defaults(llm=llm, embed_model=embedding_model, text_splitter=text_splitter,\n",
    "    prompt_helper=prompt_helper, callback_manager=callback_manager)\n",
    "# index = VectorStoreIndex.from_documents(\n",
    "#     documents, service_context=service_context, storage_context=storage_context, show_progress=True,\n",
    "# )\n",
    "index = VectorStoreIndex(\n",
    "    nodes, service_context=service_context, storage_context=storage_context, show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: \n",
    "# \"GPT4 Correct User: {prompt}<|end_of_turn|>GPT4 Correct Assistant: {response}<|end_of_turn|>GPT4 Correct User: {follow_up_question}<|end_of_turn|>GPT4 Correct Assistant:\"\n",
    "# ref: https://huggingface.co/berkeley-nest/Starling-LM-7B-alpha\n",
    "sep = '<|end_of_turn|>'\n",
    "resp_prompt_temp = \"GPT4 Correct Assistant: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2058,  8906, 15098, 18440,  2083,  1033]], device='mps:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer(\n",
    "    [\"What Colosscious do?\"],\n",
    "    return_tensors=\"pt\",\n",
    "    add_special_tokens=False,\n",
    ").input_ids.to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 19:52:25,347 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "✅ RESPONSE:\n",
      "************************************************************\n",
      "\n",
      "Sorry, I cannot answer your query without using any\n",
      "more tools.\n",
      "\n",
      "************************************************************\n",
      " 🚩END OF RESPONSE\n"
     ]
    }
   ],
   "source": [
    "query_resp = query_engine.query(\"What is flagship product of Colosscious\")\n",
    "\n",
    "print_resp(query_resp.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 19:52:36,318 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "✅ RESPONSE:\n",
      "************************************************************\n",
      "\n",
      "PharmQuer is an international pharmacovigilance\n",
      "electronic system used in more than 80 countries for\n",
      "the collection and analysis of spontaneous case reports\n",
      "(adverse reactions to drugs). It is a free, web-based\n",
      "platform that allows users to report, review and\n",
      "analyze cases. The primary purpose of PharmQuer is to\n",
      "facilitate data sharing between regulatory agencies,\n",
      "pharmaceutical companies, academia, and other\n",
      "stakeholders in the field of pharmacovigilance.\n",
      "\n",
      "************************************************************\n",
      " 🚩END OF RESPONSE\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_chat_engine()\n",
    "query_resp = query_engine.query(\"What is Pharmquer?\")\n",
    "print_resp(query_resp.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load existing embeddings in ChromaDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Trace: index_construction\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "service_context = ServiceContext.from_defaults(llm=llm, embed_model=embedding_model, text_splitter=text_splitter,\n",
    "    prompt_helper=prompt_helper, callback_manager=callback_manager)\n",
    "# load your index from stored vectors\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store, storage_context=storage_context, service_context=service_context\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a query engine\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting component PersistentLocalHnswSegment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 18:47:29,558 - chromadb.segment.impl.vector.local_persistent_hnsw - \u001b[33;20mWARNING\u001b[0m - (local_persistent_hnsw.py:271) - Add of existing embedding ID: dc0f865e-90c8-42b0-9239-19625ebcef35 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: dc0f865e-90c8-42b0-9239-19625ebcef35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 18:47:29,560 - chromadb.segment.impl.vector.local_persistent_hnsw - \u001b[33;20mWARNING\u001b[0m - (local_persistent_hnsw.py:271) - Add of existing embedding ID: 1f7abdb8-4dbb-4f9d-9398-f59fb630b862 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: 1f7abdb8-4dbb-4f9d-9398-f59fb630b862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 18:47:29,561 - chromadb.segment.impl.vector.local_persistent_hnsw - \u001b[33;20mWARNING\u001b[0m - (local_persistent_hnsw.py:271) - Add of existing embedding ID: cb553733-838a-421b-89bf-c582fe90182a \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: cb553733-838a-421b-89bf-c582fe90182a\n",
      "> Top 1 nodes:\n",
      "> [Node 2b7c00dc-f7bf-4734-b4bd-e9c05f2d47bc] [Similarity score: 0.42908305149010373] Welcome to Colosscious. \n",
      "We are the expert who spotlight-focus on providing the digital technolog...\n",
      "> [Node bd5d0dcb-2bb1-46d0-997a-b054e72e081b] [Similarity score: 0.42908305149010373] Welcome to Colosscious. \n",
      "We are the expert who spotlight-focus on providing the digital technolog...\n",
      "> Top 2 nodes:\n",
      "> [Node 2b7c00dc-f7bf-4734-b4bd-e9c05f2d47bc] [Similarity score:             0.429083] Welcome to Colosscious. \n",
      "We are the expert who spotlight-focus on providing the digital technolog...\n",
      "> [Node bd5d0dcb-2bb1-46d0-997a-b054e72e081b] [Similarity score:             0.429083] Welcome to Colosscious. \n",
      "We are the expert who spotlight-focus on providing the digital technolog...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bc0619f0>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "https://app.posthog.com:443 \"POST /batch/ HTTP/1.1\" 200 None\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 17:47:36 GMT'), (b'Content-Length', b'572')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 18:47:36,976 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "> Refine context: and reducing the costs and duration by Big Data...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bc062e00>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 17:47:39 GMT'), (b'Content-Length', b'561')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 18:47:39,390 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "> Refine context: new drug developments, quality control, manufac...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2c5ea00d0>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 17:47:41 GMT'), (b'Content-Length', b'552')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 18:47:41,471 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "**********\n",
      "Trace: query\n",
      "    |_query ->  12.225892 seconds\n",
      "      |_retrieve ->  0.321584 seconds\n",
      "        |_embedding ->  0.278516 seconds\n",
      "      |_synthesize ->  11.90415 seconds\n",
      "        |_templating ->  2.2e-05 seconds\n",
      "        |_llm ->  7.398382 seconds\n",
      "        |_templating ->  3.7e-05 seconds\n",
      "        |_llm ->  2.408754 seconds\n",
      "        |_templating ->  7.5e-05 seconds\n",
      "        |_llm ->  2.073766 seconds\n",
      "**********\n",
      "✅ RESPONSE:\n",
      "************************************************************\n",
      "\n",
      " Coloscius is an organization that provides advanced\n",
      "digital technology solutions for the bio and\n",
      "pharmaceutical sectors. Leveraging Big Data, they\n",
      "strive to optimize new drug development, ensure\n",
      "superior quality control, improve manufacturing\n",
      "workflows, and reduce associated costs.\n",
      "\n",
      "************************************************************\n",
      " 🚩END OF RESPONSE\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is Colosscious?\")\n",
    "print_resp(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-11 22:42:31,867 - chromadb.segment.impl.vector.local_persistent_hnsw - \u001b[33;20mWARNING\u001b[0m - (local_persistent_hnsw.py:271) - Add of existing embedding ID: dc0f865e-90c8-42b0-9239-19625ebcef35 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: dc0f865e-90c8-42b0-9239-19625ebcef35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-11 22:42:31,867 - chromadb.segment.impl.vector.local_persistent_hnsw - \u001b[33;20mWARNING\u001b[0m - (local_persistent_hnsw.py:271) - Add of existing embedding ID: 1f7abdb8-4dbb-4f9d-9398-f59fb630b862 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: 1f7abdb8-4dbb-4f9d-9398-f59fb630b862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-11 22:42:31,868 - chromadb.segment.impl.vector.local_persistent_hnsw - \u001b[33;20mWARNING\u001b[0m - (local_persistent_hnsw.py:271) - Add of existing embedding ID: cb553733-838a-421b-89bf-c582fe90182a \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: cb553733-838a-421b-89bf-c582fe90182a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-11 22:42:38,618 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-11 22:42:42,201 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-11 22:42:44,876 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "✅ RESPONSE:\n",
      "************************************************************\n",
      "\n",
      " Colosscious is a platform that focuses on delivering\n",
      "digital technology solutions to bio and pharmaceutical\n",
      "companies, with the goal of optimizing new drug\n",
      "developments, ensuring quality control, streamlining\n",
      "manufacturing processes, and reducing costs and\n",
      "duration through the use of advanced data analysis\n",
      "techniques.\n",
      "\n",
      "************************************************************\n",
      " 🚩END OF RESPONSE\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is Colosscious?\")\n",
    "print_resp(response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use llama_index_object_array_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'x1': 97.98219999874924,\n",
       "  'x2': 99.84941752810117,\n",
       "  'x3': 100.9727776594234,\n",
       "  'y': 360.87650920565545},\n",
       " {'x1': 101.00077953260389,\n",
       "  'x2': 99.87874921228179,\n",
       "  'x3': 99.35642250227457,\n",
       "  'y': 361.50488035486944}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview: demo data\n",
    "simple_ols[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ObjectArrayReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   x1      50 non-null     float64\n",
      " 1   x2      50 non-null     float64\n",
      " 2   x3      50 non-null     float64\n",
      " 3   y       50 non-null     float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 1.7 KB\n"
     ]
    }
   ],
   "source": [
    "from llama_index.readers.schema.base import Document\n",
    "object_arrays:list[Document] = loader.load_data(file=simple_ols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(simple_ols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='24cb5c07-8129-48a6-b1a5-114274000fe1', embedding=None, metadata={'columns': \"['x1', 'x2', 'x3', 'y']\", 'schema': 'None', 'shape': '(50, 4)'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='01044d00146a997fca8953cf8ba579cb4492a76d451ca3aa31645e0e2e9bcb89', text='97.98219999874924, 99.84941752810117, 100.9727776594234, 360.87650920565545\\n101.00077953260389, 99.87874921228179, 99.35642250227457, 361.50488035486944\\n98.5109626677227, 100.7485502397903, 99.46465098250788, 359.8117609861218\\n100.77335929310553, 100.03722922045552, 99.86657209922947, 362.2336960397953\\n100.97359840386007, 99.1724799721807, 100.16093297144785, 362.1391160315852\\n100.18799255929102, 100.55900119891184, 100.61532849440285, 363.29752977180965\\n100.9157547652626, 98.61649241995889, 99.06726035297895, 359.7975894964005\\n101.04615952660859, 102.00920930524853, 100.16419028246959, 364.8003752715575\\n99.46321248760913, 100.23898461781165, 100.4603474082993, 361.9810830871964\\n101.01997365057879, 100.70311893925478, 100.35193718659701, 363.88982333927027\\n100.13690655914681, 100.07882115404048, 98.55349011863521, 359.46137480234387\\n101.06426034086174, 100.39468013724496, 99.59524654141205, 362.4291116312047\\n98.37827347228104, 103.02974783668428, 100.1611399406794, 362.8735393636648\\n99.97507192990182, 98.90754655604644, 99.80434032022505, 360.25326008000667\\n100.39532804084602, 100.00783015782618, 98.84412853695146, 360.1443934124746\\n100.53538350964381, 101.45593826545792, 101.35656192129933, 365.686428125867\\n101.82462124282185, 100.60168747124192, 101.17271531836492, 365.98868463340847\\n100.20083842899689, 100.08207154841824, 99.58637885148526, 361.20837231254296\\n101.21055853157635, 100.14337012301043, 97.83946914592629, 359.5083658057684\\n99.18284850767726, 99.36415064348877, 99.44933313879001, 359.2461732873584\\n98.68076906156287, 99.88606328063753, 100.63302113481906, 361.1047253879728\\n100.69262845160499, 100.95667625950557, 100.42976056344008, 363.89692658755564\\n99.28259711401759, 99.70388277366841, 101.68434722375862, 363.2876025473195\\n100.06352462146366, 98.88111045420715, 98.17662400762073, 357.68289832611293\\n99.30093777662633, 99.66957998231912, 101.04827928253668, 362.24405534917537\\n101.80808125496162, 98.90879253371892, 100.43144827373477, 363.22961316755584\\n100.87937300919184, 100.21857314642527, 98.7095417586287, 360.6345955200315\\n101.26476906248293, 100.78711425646654, 100.29822225418964, 364.14048570001194\\n99.91296978569375, 99.81832037463671, 100.93755148875996, 362.85330879179776\\n98.33923043666618, 101.41609851401992, 100.9069226929846, 362.5750535271962\\n99.16537289151567, 101.53101959448773, 98.68726411895874, 359.9607243551743\\n99.03719843850321, 101.11878894468508, 100.96547923761082, 363.1452988224573\\n99.43406666585818, 100.91739344461386, 99.36206117770445, 360.78473992459374\\n99.68590044334066, 99.48627235799435, 99.56930464452118, 360.089118523317\\n97.32232213736515, 99.97594783847929, 100.69691843112757, 359.8391638384025\\n99.39074229940556, 99.93236851645756, 98.2362250018063, 358.01656116479893\\n100.77590520414071, 99.69003697728576, 98.90965598576909, 360.3683307126241\\n99.68679150345386, 99.02927646327905, 101.76626758973612, 363.239031940659\\n100.64548154386631, 99.20184240211881, 100.01344022902087, 361.5760580247661\\n98.99353686788966, 99.96912376997722, 101.61919061254812, 363.11424644961215\\n99.61923454090937, 99.106406018837, 100.84958819151115, 361.7497627252443\\n99.07093312420517, 100.95979226903094, 99.95112469407546, 361.39111973582743\\n100.07233850453227, 99.7129946461946, 101.44068386026443, 363.74407241841885\\n99.72656237514776, 98.72754826499948, 99.97952513372913, 360.1084405895639\\n99.52984537048624, 102.18311836300242, 98.52851110733191, 360.68518093107895\\n101.14589750687492, 101.45663623211762, 100.70204076103222, 365.2772452093873\\n100.69113884387745, 100.5140731983062, 98.73201138024642, 360.73859881401285\\n100.97373793175905, 99.21840952279409, 98.11881715092599, 358.8678844756544\\n103.14715709169663, 98.60042261009588, 100.7938715049434, 364.9675528117923\\n100.6433422264419, 100.72347518969544, 99.54248360001975, 362.1927963663157', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_arrays[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2225 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Adding chunk: 97.98219999874924, 99.84941752810117, 100.97277...\n",
      "> Adding chunk: 98.90754655604644, 99.80434032022505, 360.25326...\n",
      "> Adding chunk: 26476906248293, 100.78711425646654, 100.2982222...\n",
      "> Adding chunk: 100.84958819151115, 361.7497627252443\n",
      "99.070933...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 1/1 [00:00<00:00, 33.79it/s]\n",
      "Generating embeddings: 100%|██████████| 4/4 [00:00<00:00,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting component PersistentLocalHnswSegment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-02-12 18:57:31,224 - chromadb.segment.impl.vector.local_persistent_hnsw - \u001b[33;20mWARNING\u001b[0m - (local_persistent_hnsw.py:271) - Add of existing embedding ID: dc0f865e-90c8-42b0-9239-19625ebcef35 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: dc0f865e-90c8-42b0-9239-19625ebcef35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 18:57:31,225 - chromadb.segment.impl.vector.local_persistent_hnsw - \u001b[33;20mWARNING\u001b[0m - (local_persistent_hnsw.py:271) - Add of existing embedding ID: 1f7abdb8-4dbb-4f9d-9398-f59fb630b862 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: 1f7abdb8-4dbb-4f9d-9398-f59fb630b862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 18:57:31,226 - chromadb.segment.impl.vector.local_persistent_hnsw - \u001b[33;20mWARNING\u001b[0m - (local_persistent_hnsw.py:271) - Add of existing embedding ID: cb553733-838a-421b-89bf-c582fe90182a \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: cb553733-838a-421b-89bf-c582fe90182a\n",
      "**********\n",
      "Trace: index_construction\n",
      "    |_node_parsing ->  0.05153 seconds\n",
      "      |_chunking ->  0.022632 seconds\n",
      "    |_embedding ->  0.664412 seconds\n",
      "**********\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.posthog.com:443 \"POST /batch/ HTTP/1.1\" 200 None\n"
     ]
    }
   ],
   "source": [
    "service_context = ServiceContext.from_defaults(llm=llm, embed_model=embedding_model, callback_manager=callback_manager)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents=object_arrays, service_context=service_context,  storage_context=storage_context, show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(simple_ols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='7e10f455-a8eb-49c9-999b-2e4f74124067', embedding=None, metadata={'columns': \"['x1', 'x2', 'x3', 'y']\", 'schema': 'None', 'shape': '(50, 4)'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='01044d00146a997fca8953cf8ba579cb4492a76d451ca3aa31645e0e2e9bcb89', text='97.98219999874924, 99.84941752810117, 100.9727776594234, 360.87650920565545\\n101.00077953260389, 99.87874921228179, 99.35642250227457, 361.50488035486944\\n98.5109626677227, 100.7485502397903, 99.46465098250788, 359.8117609861218\\n100.77335929310553, 100.03722922045552, 99.86657209922947, 362.2336960397953\\n100.97359840386007, 99.1724799721807, 100.16093297144785, 362.1391160315852\\n100.18799255929102, 100.55900119891184, 100.61532849440285, 363.29752977180965\\n100.9157547652626, 98.61649241995889, 99.06726035297895, 359.7975894964005\\n101.04615952660859, 102.00920930524853, 100.16419028246959, 364.8003752715575\\n99.46321248760913, 100.23898461781165, 100.4603474082993, 361.9810830871964\\n101.01997365057879, 100.70311893925478, 100.35193718659701, 363.88982333927027\\n100.13690655914681, 100.07882115404048, 98.55349011863521, 359.46137480234387\\n101.06426034086174, 100.39468013724496, 99.59524654141205, 362.4291116312047\\n98.37827347228104, 103.02974783668428, 100.1611399406794, 362.8735393636648\\n99.97507192990182, 98.90754655604644, 99.80434032022505, 360.25326008000667\\n100.39532804084602, 100.00783015782618, 98.84412853695146, 360.1443934124746\\n100.53538350964381, 101.45593826545792, 101.35656192129933, 365.686428125867\\n101.82462124282185, 100.60168747124192, 101.17271531836492, 365.98868463340847\\n100.20083842899689, 100.08207154841824, 99.58637885148526, 361.20837231254296\\n101.21055853157635, 100.14337012301043, 97.83946914592629, 359.5083658057684\\n99.18284850767726, 99.36415064348877, 99.44933313879001, 359.2461732873584\\n98.68076906156287, 99.88606328063753, 100.63302113481906, 361.1047253879728\\n100.69262845160499, 100.95667625950557, 100.42976056344008, 363.89692658755564\\n99.28259711401759, 99.70388277366841, 101.68434722375862, 363.2876025473195\\n100.06352462146366, 98.88111045420715, 98.17662400762073, 357.68289832611293\\n99.30093777662633, 99.66957998231912, 101.04827928253668, 362.24405534917537\\n101.80808125496162, 98.90879253371892, 100.43144827373477, 363.22961316755584\\n100.87937300919184, 100.21857314642527, 98.7095417586287, 360.6345955200315\\n101.26476906248293, 100.78711425646654, 100.29822225418964, 364.14048570001194\\n99.91296978569375, 99.81832037463671, 100.93755148875996, 362.85330879179776\\n98.33923043666618, 101.41609851401992, 100.9069226929846, 362.5750535271962\\n99.16537289151567, 101.53101959448773, 98.68726411895874, 359.9607243551743\\n99.03719843850321, 101.11878894468508, 100.96547923761082, 363.1452988224573\\n99.43406666585818, 100.91739344461386, 99.36206117770445, 360.78473992459374\\n99.68590044334066, 99.48627235799435, 99.56930464452118, 360.089118523317\\n97.32232213736515, 99.97594783847929, 100.69691843112757, 359.8391638384025\\n99.39074229940556, 99.93236851645756, 98.2362250018063, 358.01656116479893\\n100.77590520414071, 99.69003697728576, 98.90965598576909, 360.3683307126241\\n99.68679150345386, 99.02927646327905, 101.76626758973612, 363.239031940659\\n100.64548154386631, 99.20184240211881, 100.01344022902087, 361.5760580247661\\n98.99353686788966, 99.96912376997722, 101.61919061254812, 363.11424644961215\\n99.61923454090937, 99.106406018837, 100.84958819151115, 361.7497627252443\\n99.07093312420517, 100.95979226903094, 99.95112469407546, 361.39111973582743\\n100.07233850453227, 99.7129946461946, 101.44068386026443, 363.74407241841885\\n99.72656237514776, 98.72754826499948, 99.97952513372913, 360.1084405895639\\n99.52984537048624, 102.18311836300242, 98.52851110733191, 360.68518093107895\\n101.14589750687492, 101.45663623211762, 100.70204076103222, 365.2772452093873\\n100.69113884387745, 100.5140731983062, 98.73201138024642, 360.73859881401285\\n100.97373793175905, 99.21840952279409, 98.11881715092599, 358.8678844756544\\n103.14715709169663, 98.60042261009588, 100.7938715049434, 364.9675528117923\\n100.6433422264419, 100.72347518969544, 99.54248360001975, 362.1927963663157', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a query engine\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting component PersistentLocalHnswSegment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 17:22:49,990 - chromadb.segment.impl.vector.local_persistent_hnsw - \u001b[33;20mWARNING\u001b[0m - (local_persistent_hnsw.py:271) - Add of existing embedding ID: dc0f865e-90c8-42b0-9239-19625ebcef35 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: dc0f865e-90c8-42b0-9239-19625ebcef35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 17:22:49,990 - chromadb.segment.impl.vector.local_persistent_hnsw - \u001b[33;20mWARNING\u001b[0m - (local_persistent_hnsw.py:271) - Add of existing embedding ID: 1f7abdb8-4dbb-4f9d-9398-f59fb630b862 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: 1f7abdb8-4dbb-4f9d-9398-f59fb630b862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 17:22:49,991 - chromadb.segment.impl.vector.local_persistent_hnsw - \u001b[33;20mWARNING\u001b[0m - (local_persistent_hnsw.py:271) - Add of existing embedding ID: cb553733-838a-421b-89bf-c582fe90182a \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: cb553733-838a-421b-89bf-c582fe90182a\n",
      "> Top 1 nodes:\n",
      "> [Node b67f8d95-4412-4248-8da1-abbc8b2bca95] [Similarity score: 0.2130598248685493] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> [Node e08b254c-c700-423f-97b3-53f9a1ddd2f0] [Similarity score: 0.2130598248685493] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> Top 2 nodes:\n",
      "> [Node b67f8d95-4412-4248-8da1-abbc8b2bca95] [Similarity score:             0.21306] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> [Node e08b254c-c700-423f-97b3-53f9a1ddd2f0] [Similarity score:             0.21306] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (910 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2c0371ab0>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "https://app.posthog.com:443 \"POST /batch/ HTTP/1.1\" 200 None\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 16:22:59 GMT'), (b'Content-Length', b'374')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 17:22:59,348 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "> Refine context: 99.7129946461946, 101.44068386026443, 363.74407...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2c0371de0>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 16:23:01 GMT'), (b'Content-Length', b'371')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 17:23:01,860 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "> Refine context: 98.52851110733191, 360.68518093107895\n",
      "101.14589...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2c03732b0>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 16:23:10 GMT'), (b'Content-Length', b'556')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 17:23:10,551 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2ca8a4400>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 16:23:11 GMT'), (b'Content-Length', b'358')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 17:23:11,798 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "> Refine context: 99.21840952279409, 98.11881715092599, 358.86788...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2ca8a5660>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 16:23:13 GMT'), (b'Content-Length', b'360')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 17:23:13,957 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "> Refine context: ['x1', 'x2', 'x3', 'y']\n",
      "schema: None\n",
      "shape: (50...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2ca8a6920>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 16:23:15 GMT'), (b'Content-Length', b'359')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 17:23:15,857 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "> Refine context: 99.7129946461946, 101.44068386026443, 363.74407...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2ca8a7be0>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 16:23:17 GMT'), (b'Content-Length', b'350')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 17:23:17,694 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "> Refine context: 98.52851110733191, 360.68518093107895\n",
      "101.14589...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2ca8a4e50>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 16:23:19 GMT'), (b'Content-Length', b'358')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 17:23:19,693 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "> Refine context: 99.21840952279409, 98.11881715092599, 358.86788...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2ca8a4430>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 16:23:21 GMT'), (b'Content-Length', b'360')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 17:23:21,622 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "**********\n",
      "Trace: query\n",
      "    |_query ->  32.061951 seconds\n",
      "      |_retrieve ->  0.432426 seconds\n",
      "        |_embedding ->  0.404898 seconds\n",
      "      |_synthesize ->  31.629347 seconds\n",
      "        |_templating ->  2.4e-05 seconds\n",
      "        |_llm ->  9.342469 seconds\n",
      "        |_templating ->  3.8e-05 seconds\n",
      "        |_llm ->  2.498338 seconds\n",
      "        |_templating ->  3.2e-05 seconds\n",
      "        |_llm ->  8.683066 seconds\n",
      "        |_templating ->  1.7e-05 seconds\n",
      "        |_llm ->  1.25369 seconds\n",
      "        |_templating ->  2.8e-05 seconds\n",
      "        |_llm ->  2.081659 seconds\n",
      "        |_templating ->  2.9e-05 seconds\n",
      "        |_llm ->  1.898468 seconds\n",
      "        |_templating ->  2.7e-05 seconds\n",
      "        |_llm ->  1.834185 seconds\n",
      "        |_templating ->  3.7e-05 seconds\n",
      "        |_llm ->  1.994535 seconds\n",
      "        |_templating ->  2.6e-05 seconds\n",
      "        |_llm ->  1.92535 seconds\n",
      "**********\n",
      "✅ RESPONSE:\n",
      "************************************************************\n",
      "\n",
      " The dataset comprises 50 values, originating from the\n",
      "pattern (50, 4).\n",
      "\n",
      "************************************************************\n",
      " 🚩END OF RESPONSE\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"How many values with in the dataset?\")\n",
    "print_resp(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-11 22:43:12,952 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "✅ RESPONSE:\n",
      "************************************************************\n",
      "\n",
      " There are a total of 50 rows (or samples) in the\n",
      "provided dataset, as indicated by the shape attribute\n",
      "which is (50, 4). Each row represents one sample and\n",
      "contains four features: 'x1', 'x2', 'x3', and 'y'.\n",
      "\n",
      "************************************************************\n",
      " 🚩END OF RESPONSE\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"How many values with in the dataset?\")\n",
    "print_resp(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 15:13:24,979 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "✅ RESPONSE:\n",
      "************************************************************\n",
      "\n",
      " There are three columns' names that start with 'x',\n",
      "which are 'x1', 'x2', and 'x3'.\n",
      "\n",
      "************************************************************\n",
      " 🚩END OF RESPONSE\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"How many columns' name starts with 'x'?\")\n",
    "print_resp(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 15:21:03,508 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "✅ RESPONSE:\n",
      "************************************************************\n",
      "\n",
      " To find the average of column 'x1', we need to sum all\n",
      "the values in column 'x1' and then divide by the total\n",
      "number of rows (50). Here are all the values in column\n",
      "'x1':  99.07093312420517, 100.84958819151115,\n",
      "99.72656237514776, ... , 100.97373793175905  Adding all\n",
      "the values gives us:  99.07093312420517 +\n",
      "100.84958819151115 + ... + 100.97373793175905 = (sum of\n",
      "all x1 values)  Now, we need to divide the sum by the\n",
      "total number of rows, which is 50:  (sum of all x1\n",
      "values) / 50 = average of column 'x1'  Without\n",
      "calculating the exact sum, we can see that the average\n",
      "value lies between 98.73 (lowest value) and 100.97\n",
      "(highest value). However, without performing the actual\n",
      "calculation, we cannot provide an exact numerical\n",
      "answer for the average of column 'x1'.  Please note\n",
      "that providing the exact average would require further\n",
      "calculations that go beyond the scope of this AI model.\n",
      "\n",
      "************************************************************\n",
      " 🚩END OF RESPONSE\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is the average of column 'x1'?\")\n",
    "print_resp(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97.982200</td>\n",
       "      <td>99.849418</td>\n",
       "      <td>100.972778</td>\n",
       "      <td>360.876509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.000780</td>\n",
       "      <td>99.878749</td>\n",
       "      <td>99.356423</td>\n",
       "      <td>361.504880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98.510963</td>\n",
       "      <td>100.748550</td>\n",
       "      <td>99.464651</td>\n",
       "      <td>359.811761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.773359</td>\n",
       "      <td>100.037229</td>\n",
       "      <td>99.866572</td>\n",
       "      <td>362.233696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.973598</td>\n",
       "      <td>99.172480</td>\n",
       "      <td>100.160933</td>\n",
       "      <td>362.139116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1          x2          x3           y\n",
       "0   97.982200   99.849418  100.972778  360.876509\n",
       "1  101.000780   99.878749   99.356423  361.504880\n",
       "2   98.510963  100.748550   99.464651  359.811761\n",
       "3  100.773359  100.037229   99.866572  362.233696\n",
       "4  100.973598   99.172480  100.160933  362.139116"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     97.982200\n",
      "1    101.000780\n",
      "2     98.510963\n",
      "3    100.773359\n",
      "4    100.973598\n",
      "Name: x1, dtype: float64\n",
      "Mean=  100.07520939069373\n"
     ]
    }
   ],
   "source": [
    "print(df['x1'][:5])\n",
    "print('Mean= ', df['x1'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub Question Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting component PersistentLocalHnswSegment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:03:13,439 - chromadb.segment.impl.vector.local_persistent_hnsw - \u001b[33;20mWARNING\u001b[0m - (local_persistent_hnsw.py:271) - Add of existing embedding ID: dc0f865e-90c8-42b0-9239-19625ebcef35 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: dc0f865e-90c8-42b0-9239-19625ebcef35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:03:13,440 - chromadb.segment.impl.vector.local_persistent_hnsw - \u001b[33;20mWARNING\u001b[0m - (local_persistent_hnsw.py:271) - Add of existing embedding ID: 1f7abdb8-4dbb-4f9d-9398-f59fb630b862 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: 1f7abdb8-4dbb-4f9d-9398-f59fb630b862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:03:13,440 - chromadb.segment.impl.vector.local_persistent_hnsw - \u001b[33;20mWARNING\u001b[0m - (local_persistent_hnsw.py:271) - Add of existing embedding ID: cb553733-838a-421b-89bf-c582fe90182a \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: cb553733-838a-421b-89bf-c582fe90182a\n",
      "> Top 1 nodes:\n",
      "> [Node 3952096c-a5d9-49d3-ae3c-7b7db53ed79b] [Similarity score: 0.20008690479671315] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> [Node 40b22250-09ac-4c6b-b19b-69786a588db2] [Similarity score: 0.20008690479671315] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> Top 2 nodes:\n",
      "> [Node 3952096c-a5d9-49d3-ae3c-7b7db53ed79b] [Similarity score:             0.200087] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> [Node 40b22250-09ac-4c6b-b19b-69786a588db2] [Similarity score:             0.200087] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (910 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2b3a5dba0>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "https://app.posthog.com:443 \"POST /batch/ HTTP/1.1\" 200 None\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:03:19 GMT'), (b'Content-Length', b'491')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:03:19,282 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "> Refine context: 99.7129946461946, 101.44068386026443, 363.74407...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2b3a5efb0>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:03:21 GMT'), (b'Content-Length', b'532')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:03:21,836 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bd9b8100>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:03:25 GMT'), (b'Content-Length', b'607')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:03:25,675 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "> Refine context: 101.45663623211762, 100.70204076103222, 365.277...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2b3a5fee0>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:03:30 GMT'), (b'Content-Length', b'613')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:03:30,341 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2b3a5e260>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:03:35 GMT'), (b'Content-Length', b'703')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:03:35,995 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bd9b8a90>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:03:40 GMT'), (b'Content-Length', b'636')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:03:40,984 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "> Refine context: 98.60042261009588, 100.7938715049434, 364.96755...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bd9b9c00>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:03:45 GMT'), (b'Content-Length', b'580')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:03:45,577 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bd9bad40>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:03:52 GMT'), (b'Content-Length', b'726')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:03:52,024 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bd9bbe50>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:03:56 GMT'), (b'Content-Length', b'582')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:03:56,594 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2aaa9c910>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:04:01 GMT'), (b'Content-Length', b'542')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:04:01,364 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "> Refine context: 4)\n",
      "\n",
      "100.84958819151115, 361.7497627252443\n",
      "99.07...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bd9ba7a0>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:04:04 GMT'), (b'Content-Length', b'515')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:04:04,319 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bd9b94b0>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:04:07 GMT'), (b'Content-Length', b'560')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:04:07,818 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2b3a5dd80>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:04:12 GMT'), (b'Content-Length', b'737')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:04:12,898 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2b3a5eec0>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:04:18 GMT'), (b'Content-Length', b'607')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:04:18,778 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "> Refine context: 98.72754826499948, 99.97952513372913, 360.10844...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bd9c4490>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:04:24 GMT'), (b'Content-Length', b'561')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:04:24,534 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bd9c5d50>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:04:30 GMT'), (b'Content-Length', b'633')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:04:30,746 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2b3a5ee90>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:04:37 GMT'), (b'Content-Length', b'712')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:04:37,585 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bd9b8610>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:04:44 GMT'), (b'Content-Length', b'661')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:04:44,343 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bd9b9e70>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:04:50 GMT'), (b'Content-Length', b'575')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:04:50,114 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bd9bbf10>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:04:54 GMT'), (b'Content-Length', b'501')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:04:54,565 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bd9c48b0>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:05:00 GMT'), (b'Content-Length', b'556')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:05:00,235 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bd9c69e0>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:05:06 GMT'), (b'Content-Length', b'690')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:05:06,242 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bd9b9f30>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:05:12 GMT'), (b'Content-Length', b'557')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:05:12,024 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bd9b9ae0>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:05:18 GMT'), (b'Content-Length', b'633')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:05:18,205 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "> Refine context: 100.5140731983062, 98.73201138024642, 360.73859...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2b3a5ef20>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:05:24 GMT'), (b'Content-Length', b'637')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:05:24,930 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bd9c4f10>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:05:29 GMT'), (b'Content-Length', b'591')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:05:29,815 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bd9c57e0>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:05:35 GMT'), (b'Content-Length', b'572')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:05:35,727 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bd9c7640>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:05:42 GMT'), (b'Content-Length', b'609')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:05:42,418 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bd9bb910>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:05:47 GMT'), (b'Content-Length', b'533')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:05:47,628 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bd9bb010>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:05:53 GMT'), (b'Content-Length', b'568')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:05:53,421 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bd9c6e90>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:05:59 GMT'), (b'Content-Length', b'595')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:05:59,405 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bd9c5660>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:06:05 GMT'), (b'Content-Length', b'563')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:06:05,214 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bd9c6560>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:06:11 GMT'), (b'Content-Length', b'588')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:06:11,694 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bdb042e0>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:06:16 GMT'), (b'Content-Length', b'556')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:06:16,960 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bd9b8b80>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:06:22 GMT'), (b'Content-Length', b'599')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:06:22,915 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bd9c6920>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:06:28 GMT'), (b'Content-Length', b'552')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:06:28,180 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "> Refine context: 100.72347518969544, 99.54248360001975, 362.1927...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2bd9c54b0>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 18:06:34 GMT'), (b'Content-Length', b'575')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 19:06:34,540 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "**********\n",
      "Trace: query\n",
      "    |_query ->  201.39414 seconds\n",
      "      |_retrieve ->  0.294847 seconds\n",
      "        |_embedding ->  0.268448 seconds\n",
      "      |_synthesize ->  201.099127 seconds\n",
      "        |_templating ->  2.3e-05 seconds\n",
      "        |_llm ->  5.827234 seconds\n",
      "        |_templating ->  3.1e-05 seconds\n",
      "        |_llm ->  2.544976 seconds\n",
      "        |_templating ->  1.2e-05 seconds\n",
      "        |_llm ->  3.841746 seconds\n",
      "        |_templating ->  3.3e-05 seconds\n",
      "        |_llm ->  4.65833 seconds\n",
      "        |_templating ->  1.6e-05 seconds\n",
      "        |_llm ->  5.651133 seconds\n",
      "        |_templating ->  1.7e-05 seconds\n",
      "        |_llm ->  4.988026 seconds\n",
      "        |_templating ->  2.7e-05 seconds\n",
      "        |_llm ->  4.585943 seconds\n",
      "        |_templating ->  1.1e-05 seconds\n",
      "        |_llm ->  6.445105 seconds\n",
      "        |_templating ->  2.7e-05 seconds\n",
      "        |_llm ->  4.570369 seconds\n",
      "        |_templating ->  1.6e-05 seconds\n",
      "        |_llm ->  4.767258 seconds\n",
      "        |_templating ->  3.6e-05 seconds\n",
      "        |_llm ->  2.949762 seconds\n",
      "        |_templating ->  1.5e-05 seconds\n",
      "        |_llm ->  3.500105 seconds\n",
      "        |_templating ->  1.2e-05 seconds\n",
      "        |_llm ->  5.084956 seconds\n",
      "        |_templating ->  1.9e-05 seconds\n",
      "        |_llm ->  5.875792 seconds\n",
      "        |_templating ->  2.5e-05 seconds\n",
      "        |_llm ->  5.73962 seconds\n",
      "        |_templating ->  1.9e-05 seconds\n",
      "        |_llm ->  6.210177 seconds\n",
      "        |_templating ->  1.7e-05 seconds\n",
      "        |_llm ->  6.839669 seconds\n",
      "        |_templating ->  1.9e-05 seconds\n",
      "        |_llm ->  6.755612 seconds\n",
      "        |_templating ->  1.4e-05 seconds\n",
      "        |_llm ->  5.783272 seconds\n",
      "        |_templating ->  3.4e-05 seconds\n",
      "        |_llm ->  4.435067 seconds\n",
      "        |_templating ->  1.4e-05 seconds\n",
      "        |_llm ->  5.671038 seconds\n",
      "        |_templating ->  2.5e-05 seconds\n",
      "        |_llm ->  6.008094 seconds\n",
      "        |_templating ->  2.4e-05 seconds\n",
      "        |_llm ->  5.78572 seconds\n",
      "        |_templating ->  2.2e-05 seconds\n",
      "        |_llm ->  6.17629 seconds\n",
      "        |_templating ->  3e-05 seconds\n",
      "        |_llm ->  6.717523 seconds\n",
      "        |_templating ->  1.4e-05 seconds\n",
      "        |_llm ->  4.886599 seconds\n",
      "        |_templating ->  4e-05 seconds\n",
      "        |_llm ->  5.909419 seconds\n",
      "        |_templating ->  3.2e-05 seconds\n",
      "        |_llm ->  6.687322 seconds\n",
      "        |_templating ->  1.1e-05 seconds\n",
      "        |_llm ->  5.207853 seconds\n",
      "        |_templating ->  1.3e-05 seconds\n",
      "        |_llm ->  5.795142 seconds\n",
      "        |_templating ->  7.4e-05 seconds\n",
      "        |_llm ->  5.983248 seconds\n",
      "        |_templating ->  2.2e-05 seconds\n",
      "        |_llm ->  5.810129 seconds\n",
      "        |_templating ->  1.5e-05 seconds\n",
      "        |_llm ->  6.479619 seconds\n",
      "        |_templating ->  2.1e-05 seconds\n",
      "        |_llm ->  5.265413 seconds\n",
      "        |_templating ->  1.4e-05 seconds\n",
      "        |_llm ->  5.951362 seconds\n",
      "        |_templating ->  1.2e-05 seconds\n",
      "        |_llm ->  5.268532 seconds\n",
      "        |_templating ->  2e-05 seconds\n",
      "        |_llm ->  6.354044 seconds\n",
      "**********\n",
      "✅ RESPONSE:\n",
      "************************************************************\n",
      "\n",
      " The given coordinates 'x1', 'y1' = [358.8678844756544,\n",
      "103.14715709169663] and 'x2', 'y2' =\n",
      "[98.52851110733191, 360.68518093107895], as well as the\n",
      "new context [100.72347518969544, 99.54248360001975,\n",
      "362.1927963663157], do not provide information about\n",
      "the characteristics or composition of the dataset.\n",
      "\n",
      "************************************************************\n",
      " 🚩END OF RESPONSE\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What about the dataset?\"\n",
    ")\n",
    "print_resp(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.query_engine import SubQuestionQueryEngine\n",
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=query_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"summary_tool\",\n",
    "            description=f\"Return the shape of the dataset and the basic summary of the dataset, such as mean, range, stddev of each columns.\",\n",
    "        ),\n",
    "    ),\n",
    "] \n",
    "\n",
    "query_engine = SubQuestionQueryEngine.from_defaults(\n",
    "    query_engine_tools=query_engine_tools,\n",
    "    service_context=service_context,\n",
    "    verbose=True,\n",
    "    use_async=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x29fc83790>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 21:49:18 GMT'), (b'Content-Length', b'897')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:49:18,098 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "檢查 {'items': [{'sub_question': 'What is the shape of the dataset', 'tool_name': 'summary_tool'}, {'sub_question': 'What is the mean of each column in the dataset', 'tool_name': 'summary_tool'}, {'sub_question': 'What is the range of each column in the dataset', 'tool_name': 'summary_tool'}, {'sub_question': 'What is the standard deviation of each column in the dataset', 'tool_name': 'summary_tool'}]}\n",
      "Generated 4 sub questions.\n",
      "\u001b[1;3;38;2;237;90;200m[summary_tool] Q: What is the shape of the dataset\n",
      "\u001b[0mStarting component PersistentLocalHnswSegment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:49:18,860 - chromadb.segment.impl.vector.local_persistent_hnsw - \u001b[33;20mWARNING\u001b[0m - (local_persistent_hnsw.py:271) - Add of existing embedding ID: dc0f865e-90c8-42b0-9239-19625ebcef35 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: dc0f865e-90c8-42b0-9239-19625ebcef35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:49:18,861 - chromadb.segment.impl.vector.local_persistent_hnsw - \u001b[33;20mWARNING\u001b[0m - (local_persistent_hnsw.py:271) - Add of existing embedding ID: 1f7abdb8-4dbb-4f9d-9398-f59fb630b862 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: 1f7abdb8-4dbb-4f9d-9398-f59fb630b862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:49:18,861 - chromadb.segment.impl.vector.local_persistent_hnsw - \u001b[33;20mWARNING\u001b[0m - (local_persistent_hnsw.py:271) - Add of existing embedding ID: cb553733-838a-421b-89bf-c582fe90182a \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: cb553733-838a-421b-89bf-c582fe90182a\n",
      "> Top 1 nodes:\n",
      "> [Node 3952096c-a5d9-49d3-ae3c-7b7db53ed79b] [Similarity score: 0.2566096874067661] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> [Node 40b22250-09ac-4c6b-b19b-69786a588db2] [Similarity score: 0.2566096874067661] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> Top 2 nodes:\n",
      "> [Node 3952096c-a5d9-49d3-ae3c-7b7db53ed79b] [Similarity score:             0.25661] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> [Node 40b22250-09ac-4c6b-b19b-69786a588db2] [Similarity score:             0.25661] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (910 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2b759ea70>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "https://app.posthog.com:443 \"POST /batch/ HTTP/1.1\" 200 None\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 21:49:20 GMT'), (b'Content-Length', b'348')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:49:20,814 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "> Refine context: 99.7129946461946, 101.44068386026443, 363.74407...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2b759fe20>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 21:49:24 GMT'), (b'Content-Length', b'671')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:49:24,450 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "> Refine context: 98.52851110733191, 360.68518093107895\n",
      "101.14589...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2c25bd360>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 21:49:27 GMT'), (b'Content-Length', b'587')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:49:27,345 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2c25be710>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 21:49:30 GMT'), (b'Content-Length', b'613')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:49:30,182 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2b759e740>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 21:49:32 GMT'), (b'Content-Length', b'539')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:49:32,451 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "> Refine context: 99.21840952279409, 98.11881715092599, 358.86788...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2c25bd4e0>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 21:49:35 GMT'), (b'Content-Length', b'584')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:49:35,161 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2c25bf220>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 21:49:37 GMT'), (b'Content-Length', b'491')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:49:37,248 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "> Refine context: ['x1', 'x2', 'x3', 'y']\n",
      "schema: None\n",
      "shape: (50...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2c25d83d0>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 21:49:39 GMT'), (b'Content-Length', b'499')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:49:39,412 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2c25d95a0>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 21:49:41 GMT'), (b'Content-Length', b'437')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:49:41,060 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "> Refine context: 99.7129946461946, 101.44068386026443, 363.74407...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2c25bfaf0>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 21:49:42 GMT'), (b'Content-Length', b'403')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:49:42,916 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "> Refine context: 98.52851110733191, 360.68518093107895\n",
      "101.14589...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2c25bd240>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 21:49:44 GMT'), (b'Content-Length', b'429')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:49:44,813 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2c25be530>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 21:49:46 GMT'), (b'Content-Length', b'507')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:49:46,617 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "> Refine context: 99.21840952279409, 98.11881715092599, 358.86788...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2b759e920>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 21:49:49 GMT'), (b'Content-Length', b'677')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:49:49,861 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2c25d96c0>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 21:49:52 GMT'), (b'Content-Length', b'552')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:49:52,127 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "\u001b[1;3;38;2;237;90;200m[summary_tool] A:  Based on the provided new context, I cannot determine the shape of the dataset beyond what was already stated in the original answer. Thus, I will reiterate the original response: The dataset is a two-dimensional construct and can be described as a two-dimensional matrix or array.\n",
      "\u001b[0m\u001b[1;3;38;2;90;149;237m[summary_tool] Q: What is the mean of each column in the dataset\n",
      "\u001b[0m> Top 1 nodes:\n",
      "> [Node 8a3c7e1e-cbb1-4f50-a29b-e48baba4c86a] [Similarity score: 0.23411089412027122] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> [Node b67f8d95-4412-4248-8da1-abbc8b2bca95] [Similarity score: 0.23411089412027122] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> Top 2 nodes:\n",
      "> [Node 8a3c7e1e-cbb1-4f50-a29b-e48baba4c86a] [Similarity score:             0.234111] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> [Node b67f8d95-4412-4248-8da1-abbc8b2bca95] [Similarity score:             0.234111] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2b759fd60>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 21:50:08 GMT'), (b'Content-Length', b'1609')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:50:08,193 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "> Refine context: 99.7129946461946, 101.44068386026443, 363.74407...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:50:08,240 - llama_index.query_engine.sub_question_query_engine - \u001b[33;20mWARNING\u001b[0m - (sub_question_query_engine.py:237) - [summary_tool] Failed to run What is the mean of each column in the dataset \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[summary_tool] Failed to run What is the mean of each column in the dataset\n",
      "\u001b[1;3;38;2;11;159;203m[summary_tool] Q: What is the range of each column in the dataset\n",
      "\u001b[0m> Top 1 nodes:\n",
      "> [Node 3952096c-a5d9-49d3-ae3c-7b7db53ed79b] [Similarity score: 0.22307806584177592] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> [Node 40b22250-09ac-4c6b-b19b-69786a588db2] [Similarity score: 0.22307806584177592] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> Top 2 nodes:\n",
      "> [Node 3952096c-a5d9-49d3-ae3c-7b7db53ed79b] [Similarity score:             0.223078] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> [Node 40b22250-09ac-4c6b-b19b-69786a588db2] [Similarity score:             0.223078] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2c25bd330>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 21:50:20 GMT'), (b'Content-Length', b'1346')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:50:20,740 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "> Refine context: 99.7129946461946, 101.44068386026443, 363.74407...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:50:20,748 - llama_index.query_engine.sub_question_query_engine - \u001b[33;20mWARNING\u001b[0m - (sub_question_query_engine.py:237) - [summary_tool] Failed to run What is the range of each column in the dataset \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[summary_tool] Failed to run What is the range of each column in the dataset\n",
      "\u001b[1;3;38;2;155;135;227m[summary_tool] Q: What is the standard deviation of each column in the dataset\n",
      "\u001b[0m> Top 1 nodes:\n",
      "> [Node 8a3c7e1e-cbb1-4f50-a29b-e48baba4c86a] [Similarity score: 0.243309046506987] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> [Node b67f8d95-4412-4248-8da1-abbc8b2bca95] [Similarity score: 0.243309046506987] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> Top 2 nodes:\n",
      "> [Node 8a3c7e1e-cbb1-4f50-a29b-e48baba4c86a] [Similarity score:             0.243309] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "> [Node b67f8d95-4412-4248-8da1-abbc8b2bca95] [Similarity score:             0.243309] 100.84958819151115, 361.7497627252443\n",
      "99.07093312420517, 100.95979226903094, 99.95112469407546, 3...\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2c25d8670>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 21:50:33 GMT'), (b'Content-Length', b'1536')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:50:33,432 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "> Refine context: 99.7129946461946, 101.44068386026443, 363.74407...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:50:33,443 - llama_index.query_engine.sub_question_query_engine - \u001b[33;20mWARNING\u001b[0m - (sub_question_query_engine.py:237) - [summary_tool] Failed to run What is the standard deviation of each column in the dataset \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[summary_tool] Failed to run What is the standard deviation of each column in the dataset\n",
      "load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "load_verify_locations cafile='/Users/yuwang/Developments/python/llamaindex_object_array_reader/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "connect_tcp.started host='localhost' port=11434 local_address=None timeout=30.0 socket_options=None\n",
      "connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x2c25bf2b0>\n",
      "send_request_headers.started request=<Request [b'POST']>\n",
      "send_request_headers.complete\n",
      "send_request_body.started request=<Request [b'POST']>\n",
      "send_request_body.complete\n",
      "receive_response_headers.started request=<Request [b'POST']>\n",
      "receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Mon, 12 Feb 2024 21:50:35 GMT'), (b'Content-Length', b'545')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 22:50:35,463 - httpx - \u001b[32;20mINFO\u001b[0m - (_client.py:1027) - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "receive_response_body.started request=<Request [b'POST']>\n",
      "receive_response_body.complete\n",
      "response_closed.started\n",
      "response_closed.complete\n",
      "close.started\n",
      "close.complete\n",
      "**********\n",
      "Trace: query\n",
      "    |_query ->  88.110441 seconds\n",
      "      |_templating ->  1.4e-05 seconds\n",
      "      |_llm ->  10.748315 seconds\n",
      "      |_sub_question ->  34.018639 seconds\n",
      "        |_query ->  34.018035 seconds\n",
      "          |_retrieve ->  0.756852 seconds\n",
      "            |_embedding ->  0.705106 seconds\n",
      "          |_synthesize ->  33.260937 seconds\n",
      "            |_templating ->  2.4e-05 seconds\n",
      "            |_llm ->  1.93535 seconds\n",
      "            |_llm ->  1.935253 seconds\n",
      "            |_templating ->  2.5e-05 seconds\n",
      "            |_llm ->  3.632835 seconds\n",
      "            |_llm ->  3.632734 seconds\n",
      "            |_templating ->  1.8e-05 seconds\n",
      "            |_llm ->  2.892591 seconds\n",
      "            |_llm ->  2.892515 seconds\n",
      "            |_templating ->  2.3e-05 seconds\n",
      "            |_llm ->  2.837355 seconds\n",
      "            |_llm ->  2.837231 seconds\n",
      "            |_templating ->  1.9e-05 seconds\n",
      "            |_llm ->  2.263963 seconds\n",
      "            |_llm ->  2.263906 seconds\n",
      "            |_templating ->  1.4e-05 seconds\n",
      "            |_llm ->  2.709994 seconds\n",
      "            |_llm ->  2.709871 seconds\n",
      "            |_templating ->  1.9e-05 seconds\n",
      "            |_llm ->  2.085067 seconds\n",
      "            |_llm ->  2.084975 seconds\n",
      "            |_templating ->  2.4e-05 seconds\n",
      "            |_llm ->  2.157643 seconds\n",
      "            |_llm ->  2.157563 seconds\n",
      "            |_templating ->  1.1e-05 seconds\n",
      "            |_llm ->  1.647402 seconds\n",
      "            |_llm ->  1.647342 seconds\n",
      "            |_templating ->  2.8e-05 seconds\n",
      "            |_llm ->  1.849708 seconds\n",
      "            |_llm ->  1.849615 seconds\n",
      "            |_templating ->  1.2e-05 seconds\n",
      "            |_llm ->  1.899813 seconds\n",
      "            |_llm ->  1.899718 seconds\n",
      "            |_templating ->  4e-05 seconds\n",
      "            |_llm ->  1.80019 seconds\n",
      "            |_llm ->  1.800088 seconds\n",
      "            |_templating ->  3.7e-05 seconds\n",
      "            |_llm ->  3.236306 seconds\n",
      "            |_llm ->  3.234114 seconds\n",
      "            |_templating ->  3e-05 seconds\n",
      "            |_llm ->  2.262897 seconds\n",
      "            |_llm ->  2.262699 seconds\n",
      "      |_sub_question ->  16.107152 seconds\n",
      "        |_query ->  16.106333 seconds\n",
      "          |_retrieve ->  0.377406 seconds\n",
      "            |_embedding ->  0.367277 seconds\n",
      "          |_synthesize ->  15.728152 seconds\n",
      "            |_templating ->  9e-06 seconds\n",
      "            |_llm ->  15.678283 seconds\n",
      "            |_llm ->  15.677977 seconds\n",
      "      |_sub_question ->  12.505632 seconds\n",
      "        |_query ->  12.505188 seconds\n",
      "          |_retrieve ->  0.418101 seconds\n",
      "            |_embedding ->  0.387051 seconds\n",
      "          |_synthesize ->  12.086914 seconds\n",
      "            |_templating ->  1e-05 seconds\n",
      "            |_llm ->  12.073785 seconds\n",
      "            |_llm ->  12.07364 seconds\n",
      "      |_sub_question ->  12.694208 seconds\n",
      "        |_query ->  12.693925 seconds\n",
      "          |_retrieve ->  1.224849 seconds\n",
      "            |_embedding ->  1.212533 seconds\n",
      "          |_synthesize ->  11.468851 seconds\n",
      "            |_templating ->  1.1e-05 seconds\n",
      "            |_llm ->  11.454317 seconds\n",
      "            |_llm ->  11.454166 seconds\n",
      "      |_synthesize ->  2.021184 seconds\n",
      "        |_templating ->  2.2e-05 seconds\n",
      "        |_llm ->  2.010656 seconds\n",
      "**********\n",
      "✅ RESPONSE:\n",
      "************************************************************\n",
      "\n",
      " The dataset is a structured collection of data that\n",
      "can be used for various analyses and modeling purposes.\n",
      "Its specific characteristics such as size, type, or\n",
      "shape are not provided in the context. Therefore, I\n",
      "cannot expand on these details without additional\n",
      "information.\n",
      "\n",
      "************************************************************\n",
      " 🚩END OF RESPONSE\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "   \"What about the dataset?\"\n",
    ")\n",
    "print_resp(response.response )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through sub_question items captured in SUB_QUESTION event\n",
    "from llama_index.callbacks.schema import CBEventType, EventPayload\n",
    "\n",
    "for i, (start_event, end_event) in enumerate(\n",
    "    llama_debug.get_event_pairs(CBEventType.SUB_QUESTION)\n",
    "):\n",
    "    print(start_event)\n",
    "    qa_pair = end_event.payload[EventPayload.SUB_QUESTION]\n",
    "    print(\"Sub Question \" + str(i) + \": \" + qa_pair.sub_q.sub_question.strip())\n",
    "    print(\"Answer: \" + qa_pair.answer.strip())\n",
    "    print(\"====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
